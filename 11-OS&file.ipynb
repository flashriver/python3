{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020.03.06 reviewed; 2020.03.15 reviewed; 2020.04.04 updated;  2020.07.20 reviewed     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考资料:   \n",
    "[1]<Pyhont教程>第18章文件与文件系统, DataWhale编写.         \n",
    "[2]<繁琐的工作自动化>第8章,第9章.           \n",
    "[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当程序运行时，变量是保存数据的好方法，但如果希望程序结束后数据仍然保持，就需要将数据保存到文件中。            \n",
    "你可以认为文件的内容是一个字符串值，大小可能有几个 GB。       \n",
    "\n",
    "我们所知道常用的操作系统就有：Windows，Mac OS，Linu，Unix等，这些操作系统底层对于文件系统的访问工作\n",
    "原理是不一样的，因此你可能就要针对不同的系统来考虑使用哪些文件系统模块……，这样的做法是非常不友好且\n",
    "麻烦的，因为这样就意味着当你的程序运行环境一改变，你就要相应的去修改大量的代码来应对。    \n",
    "使用 Python 的 OS 模块, 可以比较方便地在硬盘上创建、读取和保存文件。         \n",
    "有了OS（Operation System）模块，我们不需要关心什么操作系统下使用什么模块，OS模块会帮你选择正确的模块\n",
    "并调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OS模块中与文件夹相关的基础方法 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 列出文件夹下的文件与子文件夹\n",
    "* os.getcwd查看当前工作目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Py\\note\n"
     ]
    }
   ],
   "source": [
    "#查看当前工作目录,也就是当前文件所在的路径 -- get current working directory\n",
    "print(os.getcwd()) \n",
    "# 使用 print 函数格式化输出当前工作目录\n",
    "# windows系统下, 文件夹层次之间是用反斜杠 / 分割的, 但在linux/OS X 上, 是以斜杠 \\ 分割的 -- 类似于 /root/project/py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Py\\\\note'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果不格式化输出, 会发现有两个反斜杠--回忆字符串章节关于转义字符的介绍,可知 \\\\ 是用来表示 \\ 的转义字符方式.\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* os.chdir修改当前工作目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Py\n"
     ]
    }
   ],
   "source": [
    "# 如果传入的目录不存在, 会报错\n",
    "os.chdir(r'd:\\Py')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Py\\note\n"
     ]
    }
   ],
   "source": [
    "# 复原工作目录\n",
    "os.chdir(r'd:\\Py\\note')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Change the current working directory to the specified path.\n",
       "\n",
       "path may always be specified as a string.\n",
       "On some platforms, path may also be specified as an open file descriptor.\n",
       "  If this functionality is unavailable, using it raises an exception.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.chdir??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* os.listdir可以列出当前目录下的文件和子目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '00-start.ipynb',\n",
       " '01-dict.ipynb',\n",
       " '01-list.ipynb',\n",
       " '01-set.ipynb',\n",
       " '01-string.ipynb',\n",
       " '01-tuple.ipynb',\n",
       " '04-for.ipynb',\n",
       " '04-if.ipynb',\n",
       " '04-while.ipynb',\n",
       " '05-function.ipynb',\n",
       " '10-class (2).ipynb',\n",
       " '11-OS.ipynb',\n",
       " '12-exceptions.ipynb',\n",
       " '13-testing.ipynb',\n",
       " '14-matplotlib.pyplot.ipynb',\n",
       " '14-pygal.ipynb',\n",
       " '20-file.ipynb',\n",
       " '21-pymssql-wenyin&xwlw&menjin.ipynb',\n",
       " '22-pymysql-mingyuan.ipynb',\n",
       " '23-sqlalchemy-mysql.ipynb',\n",
       " '30-re-regular_expressions.ipynb',\n",
       " '30-regex-ref.ipynb',\n",
       " '30-T&D wrangling.ipynb',\n",
       " '40-numpy.ipynb',\n",
       " '50-pandas.ipynb',\n",
       " '70-http.ipynb',\n",
       " '90-pygame-1.ipynb',\n",
       " 'data',\n",
       " 'datetime.ipynb',\n",
       " 'formula.xls',\n",
       " 'log.txt',\n",
       " 'python_cookbook',\n",
       " 'style.xlsx',\n",
       " 'test11.xlsx',\n",
       " 'test315',\n",
       " 'test316',\n",
       " 'test316_1',\n",
       " 'Untitled.ipynb',\n",
       " 'wrd_xwcs.ipynb',\n",
       " 'XY-ZY修订.ipynb',\n",
       " '副本材料科学与工程学院本科毕业生需办理离校手续清单.xlsx']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取指定路径下的所有文件和子目录\n",
    "[f for f in os.listdir('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.ipynb_checkpoints',\n",
       " '111.txt',\n",
       " '16-cx_Oracle.ipynb',\n",
       " 'A.A.ipynb',\n",
       " 'arrays_compressed.npz',\n",
       " 'array_archive.npz',\n",
       " 'bak',\n",
       " 'BYS612-yuyue.csv',\n",
       " 'C04.ipynb',\n",
       " 'C05-extend.ipynb',\n",
       " 'C05.ipynb',\n",
       " 'C06.ipynb',\n",
       " 'C07.ipynb',\n",
       " 'C08.ipynb',\n",
       " 'C09.ipynb',\n",
       " 'C10.ipynb',\n",
       " 'C11.ipynb',\n",
       " 'C12.ipynb',\n",
       " 'ch02.ipynb',\n",
       " 'datasets',\n",
       " 'dis.csv',\n",
       " 'dis.txt',\n",
       " 'dis1 (2).csv',\n",
       " 'dis1.csv',\n",
       " 'dis2.csv',\n",
       " 'distu - 副本.txt',\n",
       " 'distu.txt',\n",
       " 'example.csv',\n",
       " 'examples',\n",
       " 'figpath.jpeg',\n",
       " 'figpath.png',\n",
       " 'figpath.svg',\n",
       " 'json.json',\n",
       " 'LICENSE.txt',\n",
       " 'mat1.csv',\n",
       " 'mat1.txt',\n",
       " 'mingyuan-1.xlsx',\n",
       " 'mingyuan.xlsx',\n",
       " 'mydata - 副本.h5',\n",
       " 'mydata.h5',\n",
       " 'mydata.ht',\n",
       " 'mydata.sqlite',\n",
       " 'mydata315.h5',\n",
       " 'netCDF4--nc file.ipynb',\n",
       " 'new.txt',\n",
       " 'new1',\n",
       " 'new1.bak',\n",
       " 'new2',\n",
       " 'new2.bak',\n",
       " 'PPT.html',\n",
       " 'pydata-book-2nd-edition',\n",
       " 'readme.txt',\n",
       " 'ref.csv',\n",
       " 'ref.csv.bak',\n",
       " 'ref.csv.bak.bak',\n",
       " 'ref.xls',\n",
       " 'ref.xlsx',\n",
       " 'ref1.csv',\n",
       " 'ref1.txt',\n",
       " 'ref1.txt.bak',\n",
       " 'ref1.txt.bak.bak',\n",
       " 'ref22.xls',\n",
       " 'ref22_w2.xlsx',\n",
       " 'ref22_writer.xlsx',\n",
       " 'ref_w2.xlsx',\n",
       " 'ref_writer.xlsx',\n",
       " 'shumujiluhao-564.csv',\n",
       " 'some_array.npy',\n",
       " 'sst.mnmean.nc',\n",
       " 'test.mycsv',\n",
       " 'test.txt',\n",
       " 'ts.csv',\n",
       " 'Untitled1.ipynb',\n",
       " 'XWLW_data_wrangling.ipynb',\n",
       " '会议PPT_CALIS第十七届引进数据库培训周 - 吉林大学图书馆_files',\n",
       " '表7-5.png']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 列表推导式并不是必须的\n",
    "os.listdir(r'D:\\Py\\Pyda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', '00-start.ipynb', '01-dict.ipynb', '01-list.ipynb', '01-set.ipynb', '01-string.ipynb', '01-tuple.ipynb', '04-for.ipynb', '04-if.ipynb', '04-while.ipynb', '05-function.ipynb', '10-class (2).ipynb', '11-OS.ipynb', '12-exceptions.ipynb', '13-testing.ipynb', '14-matplotlib.pyplot.ipynb', '14-pygal.ipynb', '20-file.ipynb', '21-pymssql-wenyin&xwlw&menjin.ipynb', '22-pymysql-mingyuan.ipynb', '23-sqlalchemy-mysql.ipynb', '30-re-regular_expressions.ipynb', '30-regex-ref.ipynb', '30-T&D wrangling.ipynb', '40-numpy.ipynb', '50-pandas.ipynb', '70-http.ipynb', '90-pygame-1.ipynb', 'data', 'datetime.ipynb', 'formula.xls', 'log.txt', 'python_cookbook', 'style.xlsx', 'test11.xlsx', 'test315', 'test316', 'test316_1', 'Untitled.ipynb', 'wrd_xwcs.ipynb', 'XY-ZY修订.ipynb', '副本材料科学与工程学院本科毕业生需办理离校手续清单.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# 获取当前文件夹下所有的文件--只能获取传入参数目录下的子文件夹和文件, 不能深层获取\n",
    "print(os.listdir()) #　不传入参数就默认使用当前工作目录\n",
    "# 使用print函数可以显示得更紧凑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6DC7933', 'aaRemove.exe', 'addins', 'amlog', 'ampa.exe', 'ampa.ini', 'AppCompat', 'AppPatch', 'assembly', 'bfsvc.exe', 'BitLockerDiscoveryVolumeContents', 'Boot', 'bootstat.dat', 'Branding', 'CSC', 'Cursors', 'D8Ecap.exe', 'debug', 'diagnostics', 'DigitalLocker', 'Downloaded Program Files', 'en-US', 'explorer.exe', 'Fonts', 'fveupdate.exe', 'Globalization', 'Help', 'HelpPane.exe', 'hh.exe', 'IME', 'inf', 'Installer', 'ISTask.dll', 'L2Schemas', 'LiveKernelReports', 'Logs', 'Media', 'mib.bin', 'Microsoft.NET', 'Migration', 'ModemLogs', 'msdfmap.ini', 'notepad.exe', 'NvContainerRecovery.bat', 'Offline Web Pages', 'panther', 'pc', 'Performance', 'PFRO.log', 'PLA', 'PolicyDefinitions', 'Prefetch', 'psnetwork.ini', 'regedit.exe', 'Registration', 'RemotePackages', 'rescache', 'Resources', 'ScData', 'SchCache', 'schemas', 'security', 'ServiceProfiles', 'servicing', 'Setup', 'setupact.log', 'setuperr.log', 'SoftwareDistribution', 'splwow64.exe', 'Starter.xml', 'system', 'system.ini', 'System32', 'SysWOW64', 'TAPI', 'Tasks', 'Temp', 'tracing', 'twain.dll', 'twain_32', 'twain_32.dll', 'twunk_16.exe', 'twunk_32.exe', 'Ultimate.xml', 'Vss', 'Web', 'win.ini', 'WindowsShell.Manifest', 'WindowsUpdate.log', 'winhlp32.exe', 'winsxs', 'WMSysPr9.prx', 'write.exe', 'wxb', 'zh-CN', '~GLC0000.TMP', '~GLC0001.TMP', '~GLH0000.TMP', '~GLH0001.TMP']\n",
      "['6DC7933', 'aaRemove.exe', 'addins', 'amlog', 'ampa.exe', 'ampa.ini', 'AppCompat', 'AppPatch', 'assembly', 'bfsvc.exe', 'BitLockerDiscoveryVolumeContents', 'Boot', 'bootstat.dat', 'Branding', 'CSC', 'Cursors', 'D8Ecap.exe', 'debug', 'diagnostics', 'DigitalLocker', 'Downloaded Program Files', 'en-US', 'explorer.exe', 'Fonts', 'fveupdate.exe', 'Globalization', 'Help', 'HelpPane.exe', 'hh.exe', 'IME', 'inf', 'Installer', 'ISTask.dll', 'L2Schemas', 'LiveKernelReports', 'Logs', 'Media', 'mib.bin', 'Microsoft.NET', 'Migration', 'ModemLogs', 'msdfmap.ini', 'notepad.exe', 'NvContainerRecovery.bat', 'Offline Web Pages', 'panther', 'pc', 'Performance', 'PFRO.log', 'PLA', 'PolicyDefinitions', 'Prefetch', 'psnetwork.ini', 'regedit.exe', 'Registration', 'RemotePackages', 'rescache', 'Resources', 'ScData', 'SchCache', 'schemas', 'security', 'ServiceProfiles', 'servicing', 'Setup', 'setupact.log', 'setuperr.log', 'SoftwareDistribution', 'splwow64.exe', 'Starter.xml', 'system', 'system.ini', 'System32', 'SysWOW64', 'TAPI', 'Tasks', 'Temp', 'tracing', 'twain.dll', 'twain_32', 'twain_32.dll', 'twunk_16.exe', 'twunk_32.exe', 'Ultimate.xml', 'Vss', 'Web', 'win.ini', 'WindowsShell.Manifest', 'WindowsUpdate.log', 'winhlp32.exe', 'winsxs', 'WMSysPr9.prx', 'write.exe', 'wxb', 'zh-CN', '~GLC0000.TMP', '~GLC0001.TMP', '~GLH0000.TMP', '~GLH0001.TMP']\n",
      "['6DC7933', 'aaRemove.exe', 'addins', 'amlog', 'ampa.exe', 'ampa.ini', 'AppCompat', 'AppPatch', 'assembly', 'bfsvc.exe', 'BitLockerDiscoveryVolumeContents', 'Boot', 'bootstat.dat', 'Branding', 'CSC', 'Cursors', 'D8Ecap.exe', 'debug', 'diagnostics', 'DigitalLocker', 'Downloaded Program Files', 'en-US', 'explorer.exe', 'Fonts', 'fveupdate.exe', 'Globalization', 'Help', 'HelpPane.exe', 'hh.exe', 'IME', 'inf', 'Installer', 'ISTask.dll', 'L2Schemas', 'LiveKernelReports', 'Logs', 'Media', 'mib.bin', 'Microsoft.NET', 'Migration', 'ModemLogs', 'msdfmap.ini', 'notepad.exe', 'NvContainerRecovery.bat', 'Offline Web Pages', 'panther', 'pc', 'Performance', 'PFRO.log', 'PLA', 'PolicyDefinitions', 'Prefetch', 'psnetwork.ini', 'regedit.exe', 'Registration', 'RemotePackages', 'rescache', 'Resources', 'ScData', 'SchCache', 'schemas', 'security', 'ServiceProfiles', 'servicing', 'Setup', 'setupact.log', 'setuperr.log', 'SoftwareDistribution', 'splwow64.exe', 'Starter.xml', 'system', 'system.ini', 'System32', 'SysWOW64', 'TAPI', 'Tasks', 'Temp', 'tracing', 'twain.dll', 'twain_32', 'twain_32.dll', 'twunk_16.exe', 'twunk_32.exe', 'Ultimate.xml', 'Vss', 'Web', 'win.ini', 'WindowsShell.Manifest', 'WindowsUpdate.log', 'winhlp32.exe', 'winsxs', 'WMSysPr9.prx', 'write.exe', 'wxb', 'zh-CN', '~GLC0000.TMP', '~GLC0001.TMP', '~GLH0000.TMP', '~GLH0001.TMP']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('c:/windows')) #注意用的是反斜杠 -- 也可以用双斜杠,或者在字符串前加 r 表示原始字符串而不进行\"转义\"\n",
    "print(os.listdir('c:\\\\windows'))\n",
    "print(os.listdir(r'c:\\windows'))\n",
    "#获取指定路径下的所有文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如何同时获取子目录下的文件名?   \n",
    "  使用递归可以实现."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Return a list containing the names of the files in the directory.\n",
       "\n",
       "path can be specified as either str, bytes, or a path-like object.  If path is bytes,\n",
       "  the filenames returned will also be bytes; in all other circumstances\n",
       "  the filenames returned will be str.\n",
       "If path is None, uses the path='.'.\n",
       "On some platforms, path may also be specified as an open file descriptor;\\\n",
       "  the file descriptor must refer to a directory.\n",
       "  If this functionality is unavailable, using it raises NotImplementedError.\n",
       "\n",
       "The list is in arbitrary order.  It does not include the special\n",
       "entries '.' and '..' even if they are present in the directory.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.listdir??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查路径或文件的有效性\n",
    "* os.path.isdir       \n",
    "    检查是否是文件夹          \n",
    "* os.path.isfile    \n",
    "    检查是否是文件      \n",
    "* os.path.exists     \n",
    "    检查是否存在,可检查文件夹也可以检查文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查是否是文件夹\n",
    "os.path.isdir(r'D:\\Py\\note\\test43')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#检查路径是否存在\n",
    "os.path.exists(r'D:\\Py\\note\\test43')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查文件夹是否存在\n",
    "os.path.exists(r'D:\\Py\\note\\log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查文件是否存在(传入目录总是False)\n",
    "os.path.isfile(r'D:\\Py\\note\\log.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建文件夹\n",
    "* 使用mkdir() 命令在指定的路径下创建一个文件夹 -- 1.只能在已经存在的目录下创建单层目录;2.如果该目录已存在抛出异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(r'D:\\Py\\note\\test722')\n",
    "# 创建成功时, 并没有返回值."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '00-start.ipynb',\n",
       " '01-dict.ipynb',\n",
       " '01-list.ipynb',\n",
       " '01-set.ipynb',\n",
       " '01-string.ipynb',\n",
       " '01-tuple.ipynb',\n",
       " '04-for.ipynb',\n",
       " '04-if.ipynb',\n",
       " '04-while.ipynb',\n",
       " '05-function.ipynb',\n",
       " '10-class (2).ipynb',\n",
       " '11-OS.ipynb',\n",
       " '12-exceptions.ipynb',\n",
       " '13-testing.ipynb',\n",
       " '14-matplotlib.pyplot.ipynb',\n",
       " '14-pygal.ipynb',\n",
       " '20-file.ipynb',\n",
       " '21-pymssql-wenyin&xwlw&menjin.ipynb',\n",
       " '22-pymysql-mingyuan.ipynb',\n",
       " '23-sqlalchemy-mysql.ipynb',\n",
       " '30-re-regular_expressions.ipynb',\n",
       " '30-regex-ref.ipynb',\n",
       " '30-T&D wrangling.ipynb',\n",
       " '40-numpy.ipynb',\n",
       " '50-pandas.ipynb',\n",
       " '70-http.ipynb',\n",
       " '90-pygame-1.ipynb',\n",
       " 'data',\n",
       " 'datetime.ipynb',\n",
       " 'formula.xls',\n",
       " 'log.txt',\n",
       " 'python_cookbook',\n",
       " 'style.xlsx',\n",
       " 'test11.xlsx',\n",
       " 'test315',\n",
       " 'test316',\n",
       " 'test316_1',\n",
       " 'test719',\n",
       " 'Untitled.ipynb',\n",
       " 'wrd_xwcs.ipynb',\n",
       " 'XY-ZY修订.ipynb',\n",
       " '副本材料科学与工程学院本科毕业生需办理离校手续清单.xlsx']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用listdir查看发现,创建成功\n",
    "os.listdir(r'D:\\Py\\note')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] 当文件已存在时，无法创建该文件。: 'D:\\\\Py\\\\note\\\\test722'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-175-4f46d4c3eaef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\Py\\note\\test722'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# 创建成功时, 并没有返回值.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] 当文件已存在时，无法创建该文件。: 'D:\\\\Py\\\\note\\\\test722'"
     ]
    }
   ],
   "source": [
    "os.mkdir(r'D:\\Py\\note\\test722')\n",
    "# 已存在时会报错\n",
    "# FileExistsError: [WinError 183] 当文件已存在时，无法创建该文件。: 'D:\\\\Py\\\\note\\\\test722'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'D:\\\\Py\\\\note\\\\test722\\\\722\\\\dir1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-0526c89a5d8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 创建层叠文件夹时会报错\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\Py\\note\\test722\\722\\dir1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# FileNotFoundError: [WinError 3] 系统找不到指定的路径。: 'D:\\\\Py\\\\note\\\\test719\\\\722\\\\dir1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'D:\\\\Py\\\\note\\\\test722\\\\722\\\\dir1'"
     ]
    }
   ],
   "source": [
    "# 创建层叠文件夹时会报错\n",
    "os.mkdir(r'D:\\Py\\note\\test722\\722\\dir1')\n",
    "# FileNotFoundError: [WinError 3] 系统找不到指定的路径。: 'D:\\\\Py\\\\note\\\\test719\\\\722\\\\dir1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* os.makedirs 可以创建多层文件夹(注意结尾有s) -- 递归创建多层目录，如果该目录已存在抛出异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在指定的路径下创建一个文件夹\n",
    "os.makedirs('D:\\\\Py\\\\note\\\\test722\\\\722\\\\dir1') #使用双斜杠\n",
    "# 完成创建后没有反馈\n",
    "# 重复创建文件夹会报错 -- FileExistsError: [WinError 183] 当文件已存在时，无法创建该文件。: 'D:\\\\Python\\\\note\\\\test316_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用listdir查看发现,创建成功\n",
    "'dir1' in os.listdir('D:\\\\Py\\\\note\\\\test722\\\\722')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 结合检查路径有效性的方法, 检查路径是否存在, 如果不存在就创建\n",
    "os.path.isdir('D:\\\\Py\\\\note\\\\test42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkandmake(path):\n",
    "    if os.path.isdir(path):\n",
    "        print('\"{}\"已存在'.format(path))\n",
    "    else :\n",
    "        os.makedirs(path)\n",
    "        print('\"{}\"已创建'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"D:\\Py\\note\\test42\"已创建\n"
     ]
    }
   ],
   "source": [
    "checkandmake('D:\\\\Py\\\\note\\\\test42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"D:\\Py\\note\\test42\"已存在\n"
     ]
    }
   ],
   "source": [
    "checkandmake('D:\\\\Py\\\\note\\\\test42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m511\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;32mdef\u001b[0m \u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0o777\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\"makedirs(name [, mode=0o777][, exist_ok=False])\n",
       "\n",
       "    Super-mkdir; create a leaf directory and all intermediate ones.  Works like\n",
       "    mkdir, except that any intermediate path segment (not just the rightmost)\n",
       "    will be created if it does not exist. If the target directory already\n",
       "    exists, raise an OSError if exist_ok is False. Otherwise no exception is\n",
       "    raised.  This is recursive.\n",
       "\n",
       "    \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mhead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtail\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mhead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mhead\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtail\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# Defeats race condition when another thread created the path\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mpass\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurdir\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mcdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ASCII'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mtail\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcdir\u001b[0m\u001b[1;33m:\u001b[0m           \u001b[1;31m# xxx/newdir/. exists if xxx/newdir exists\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mreturn\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# could give priority to other errors like EACCES or EROFS\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexist_ok\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\programdata\\anaconda3\\lib\\os.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重命名文件(或文件夹)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重命名文件(或文件夹)\n",
    "os.rename('test42','test42--new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_dir_fd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst_dir_fd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Rename a file or directory.\n",
       "\n",
       "If either src_dir_fd or dst_dir_fd is not None, it should be a file\n",
       "  descriptor open to a directory, and the respective path string (src or dst)\n",
       "  should be relative; the path will then be relative to that directory.\n",
       "src_dir_fd and dst_dir_fd, may not be implemented on your platform.\n",
       "  If they are unavailable, using them will raise a NotImplementedError.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.rename??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际工作场景中,经常会有一些批量重命名文件的需求.   \n",
    "考虑如下问题: 从某数据库下载的全文文件均为字符和数字混合的命名方式, 现在希望用文章标题对文件名进行重命名. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-s2.0-S0096300312006704-main.pdf',\n",
       " '1-s2.0-S0096300312009551-main.pdf',\n",
       " '1-s2.0-S0096300313000052-main.pdf',\n",
       " '1-s2.0-S0165168411001010-main.pdf',\n",
       " '1-s2.0-S0377042710005030-main.pdf',\n",
       " '1-s2.0-S0377042712001045-main.pdf',\n",
       " '1-s2.0-S0377042712001586-main.pdf',\n",
       " '1-s2.0-S0893965912000778-main.pdf',\n",
       " '1-s2.0-S0893965912001395-main.pdf',\n",
       " '1-s2.0-S1007570405000341-main.pdf',\n",
       " '1-s2.0-S2210650211000721-main.pdf']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filelist = dirfiles(r'C:\\Users\\Administrator\\Documents\\NoteExpress\\Libraries\\FullText\\sd')\n",
    "import re\n",
    "filepath = r'C:\\Users\\Administrator\\Documents\\NoteExpress\\Libraries\\FullText\\sd'\n",
    "filelist = [i for i in os.listdir(filepath) if re.search('main.pdf$',i)]\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = ['Some efficient derivative free methods with memory for solving nonlinear equations',\n",
    "'A derivative-free method for solving box-constrained underdetermined nonlinear systems of equations',\n",
    "'Superlinear bracketing method for solving nonlinear equations',\n",
    "'A tracker-aware detector threshold optimization formulation for tracking maneuvering targets in clutter',\n",
    "'Steffensen type methods for solving nonlinear equations',\n",
    "'Iterative methods for solving nonlinear equations with finitely many roots in an interval',\n",
    "'A new technique to obtain derivative-free optimal iterative methods for solving nonlinear equations',\n",
    "'Combined bracketing methods for solving nonlinear equations',\n",
    "'A cubically convergent Steffensen-like method for solving nonlinear equations',\n",
    "'Unscented fuzzy-controlled current statistic model and adaptive filtering for tracking maneuvering targets',\n",
    "'An interacting Fuzzy-Fading-Memory-based Augmented Kalman Filtering method for maneuvering target tracking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filelist),len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\1-s2.0-S0096300312006704-main.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\1-s2.0-S0096300312009551-main.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\1-s2.0-S0096300313000052-main.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\1-s2.0-S0165168411001010-main.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\1-s2.0-S0377042710005030-main.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\1-s2.0-S0377042712001045-main.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\1-s2.0-S0377042712001586-main.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\1-s2.0-S0893965912000778-main.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\1-s2.0-S0893965912001395-main.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\1-s2.0-S1007570405000341-main.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\1-s2.0-S2210650211000721-main.pdf']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullpath = [os.path.join(filepath,i) for i in filelist]\n",
    "fullpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\Some efficient derivative free methods with memory for solving nonlinear equations.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\A derivative-free method for solving box-constrained underdetermined nonlinear systems of equations.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\Superlinear bracketing method for solving nonlinear equations.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\A tracker-aware detector threshold optimization formulation for tracking maneuvering targets in clutter.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\Steffensen type methods for solving nonlinear equations.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\Iterative methods for solving nonlinear equations with finitely many roots in an interval.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\A new technique to obtain derivative-free optimal iterative methods for solving nonlinear equations.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\Combined bracketing methods for solving nonlinear equations.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\A cubically convergent Steffensen-like method for solving nonlinear equations.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\Unscented fuzzy-controlled current statistic model and adaptive filtering for tracking maneuvering targets.pdf',\n",
       " 'C:\\\\Users\\\\Administrator\\\\Documents\\\\NoteExpress\\\\Libraries\\\\FullText\\\\sd\\\\An interacting Fuzzy-Fading-Memory-based Augmented Kalman Filtering method for maneuvering target tracking.pdf']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newnames = [os.path.join(filepath,i)+'.pdf' for i in title]\n",
    "newnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fullpath)):\n",
    "    os.rename(fullpath[i],newnames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A cubically convergent Steffensen-like method for solving nonlinear equations.pdf',\n",
       " 'A derivative-free method for solving box-constrained underdetermined nonlinear systems of equations.pdf',\n",
       " 'A new technique to obtain derivative-free optimal iterative methods for solving nonlinear equations.pdf',\n",
       " 'A tracker-aware detector threshold optimization formulation for tracking maneuvering targets in clutter.pdf',\n",
       " 'An interacting Fuzzy-Fading-Memory-based Augmented Kalman Filtering method for maneuvering target tracking.pdf',\n",
       " 'Combined bracketing methods for solving nonlinear equations.pdf',\n",
       " 'Iterative methods for solving nonlinear equations with finitely many roots in an interval.pdf',\n",
       " 'Some efficient derivative free methods with memory for solving nonlinear equations.pdf',\n",
       " 'Steffensen type methods for solving nonlinear equations.pdf',\n",
       " 'Superlinear bracketing method for solving nonlinear equations.pdf',\n",
       " 'Unscented fuzzy-controlled current statistic model and adaptive filtering for tracking maneuvering targets.pdf']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查修改结果\n",
    "[i for i in os.listdir(filepath) if re.search('.pdf$',i)]\n",
    "# 修改成功"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除文件或文件夹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 删除文件夹  \n",
    "    * os.rmdir(path) 用于删除单层目录。仅当这文件夹是空的才可以, 否则, 抛出 OSError 。\n",
    "    * os.removedirs(path) 递归删除目录，从子目录到父目录逐层尝试删除，遇到目录非空则抛出异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremovedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;32mdef\u001b[0m \u001b[0mremovedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\"removedirs(name)\n",
       "\n",
       "    Super-rmdir; remove a leaf directory and all empty intermediate\n",
       "    ones.  Works like rmdir except that, if the leaf directory is\n",
       "    successfully removed, directories corresponding to rightmost path\n",
       "    segments will be pruned away until either the whole path is\n",
       "    consumed or an error occurs.  Errors during this latter phase are\n",
       "    ignored -- they generally mean that a directory was not empty.\n",
       "\n",
       "    \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrmdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mhead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtail\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mhead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mwhile\u001b[0m \u001b[0mhead\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtail\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mrmdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mbreak\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mhead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\programdata\\anaconda3\\lib\\os.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.removedirs??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 删除文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function remove in module nt:\n",
      "\n",
      "remove(path, *, dir_fd=None)\n",
      "    Remove a file (same as unlink()).\n",
      "    \n",
      "    If dir_fd is not None, it should be a file descriptor open to a directory,\n",
      "      and path should be relative; path will then be relative to that directory.\n",
      "    dir_fd may not be implemented on your platform.\n",
      "      If it is unavailable, using it will raise a NotImplementedError.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(os.remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 移动文件或文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件路径的拆分\n",
    "* os.path.dirname(path)  \n",
    "    将返回path的最后一个斜杠之前的所有内容,也就是该文件夹(或文件)所在的文件夹    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\ProgramData'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回文件夹所在的父文件夹\n",
    "os.path.dirname('D:\\ProgramData\\Anaconda3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Python\\\\note\\\\data'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回文件所在的文件夹\n",
    "os.path.dirname('D:\\\\Python\\\\note\\\\data\\\\test2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Python\\\\note'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 递归调用, 则显示文件所在文件夹的父文件夹\n",
    "os.path.dirname(os.path.dirname('D:\\\\Python\\\\note\\\\data\\\\test2.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以传入相对路径,可以得到该相对路径所位于的文件夹\n",
    "os.path.dirname('.\\data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* os.path.basename() 返回文件的文件名,或文件夹的名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test2.txt'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename('D:\\\\Py\\\\note\\\\data\\\\test2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename('D:\\\\Py\\\\note\\\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename('D:\\\\Py\\\\note\\\\data\\\\')\n",
    "# 这时返回的是个空字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* os.path.sep 属性,返回当前操作系统所支持的文件路径分隔符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\\\', str)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.sep,type(os.path.sep)\n",
    "# 如果是 linux/OS X 则会返回 /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* os.path.split 将路径分拆为dirname和basename的二元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D:\\\\Py\\\\note\\\\data', 'test2.txt')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.split('D:\\\\Py\\\\note\\\\data\\\\test2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D:\\\\Py\\\\note', 'data')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.split('D:\\\\Py\\\\note\\\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D:\\\\Py\\\\note\\\\data', '')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.split('D:\\\\Py\\\\note\\\\data\\\\')\n",
    "# 注意文件夹最后多了分隔符后,和上边是有区别的\n",
    "# 这说明os.path.split 方法是用最后一个分隔符来进行分割的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\"Split a pathname.\n",
       "\n",
       "    Return tuple (head, tail) where tail is everything after the final slash.\n",
       "    Either part may be empty.\"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mseps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_bothseps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitdrive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# set i to index beyond p's last slash\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mi\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mhead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# now tail has no slashes\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# remove trailing slashes from head, unless it's all slashes\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mhead\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhead\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mhead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtail\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\programdata\\anaconda3\\lib\\ntpath.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.path.split??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Return the file system path representation of the object.\n",
       "\n",
       "If the object is str or bytes, then allow it to pass through as-is. If the\n",
       "object defines __fspath__(), then return the result of that method. All other\n",
       "types raise a TypeError.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.fspath??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 使用字符串的属性方法split, 按照操作系统支持的路径分隔符进行分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D:\\\\Py\\\\note\\\\data\\\\test2.txt', str)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'D:\\\\Py\\\\note\\\\data\\\\test2.txt'\n",
    "filepath,type(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:', 'Py', 'note', 'data', 'test2.txt']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = filepath.split(os.path.sep)\n",
    "lst\n",
    "# 拆分为一个list--会自动根据操作系统来使用正确的路径分隔符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Py\\\\note\\\\data\\\\test2.txt'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用字符串的join方法,将列表中的字符串连接成有效路径--会自动根据操作系统来使用正确的路径分隔符\n",
    "os.path.sep.join(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件路径的组合\n",
    "\n",
    "* os.path.join()    \n",
    "    该方法将传入的多个字符串用os.path.sep连接起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Py\\\\note'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(lst[1],lst[2]) # 会自动根据操作系统来使用正确的路径分隔符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-ca8a116f6b22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 不能直接传入list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\ntpath.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m# Join two (or more) paths.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb'\\\\'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list"
     ]
    }
   ],
   "source": [
    "# 不能直接传入list\n",
    "os.path.join(filepath.split(os.path.sep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-c07a06baa5ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 不能直接传入list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\ntpath.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m# Join two (or more) paths.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb'\\\\'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list"
     ]
    }
   ],
   "source": [
    "# 不能直接传入list\n",
    "os.path.join(lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-7acb7b44c708>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\ntpath.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m# Join two (or more) paths.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb'\\\\'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not tuple"
     ]
    }
   ],
   "source": [
    "# tuple也不行\n",
    "os.path.join(tuple(lst)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Py\\\\note\\\\data\\\\test2.txt'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对上述法遇到的问题的解决方案之一\n",
    "os.path.sep.join(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Py\\\\note\\\\data\\\\test2.txt'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.path.dirname(filepath),os.path.basename(filepath))\n",
    "# 必须传入多个字符串类型的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Py\\\\note\\\\data\\\\test2.txt'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.path.dirname(os.path.dirname(filepath)),os.path.dirname(filepath),os.path.basename(filepath))\n",
    "# 组合会去重?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D:\\\\Py\\\\note', 'D:\\\\Py\\\\note\\\\data', 'test2.txt')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(os.path.dirname(filepath)),os.path.dirname(filepath),os.path.basename(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Py\\\\note\\\\data\\\\test2.txt'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join('D:\\\\Py\\\\note', 'D:\\\\Py\\\\note\\\\data', 'test2.txt')\n",
    "# 传入的路径有重合的层级时, 会自动识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb'\\\\'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mseps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb'\\\\/'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcolon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb':'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mseps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\\\/'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcolon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msep\u001b[0m  \u001b[1;31m#23780: Ensure compatible data type even if p is null.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mresult_drive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitdrive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mp_drive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitdrive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mp_path\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mp_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# Second path is absolute\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mp_drive\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult_drive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mresult_drive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp_drive\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mresult_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp_path\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32melif\u001b[0m \u001b[0mp_drive\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mp_drive\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mresult_drive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mp_drive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mresult_drive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;31m# Different drives => ignore the first path entirely\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mresult_drive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp_drive\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mresult_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp_path\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# Same drive in different case\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mresult_drive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp_drive\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# Second path is relative to the first\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mresult_path\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mresult_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mresult_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mp_path\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m## add separator between UNC and non-absolute path\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresult_path\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseps\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mresult_drive\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresult_drive\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mcolon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mresult_drive\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mresult_drive\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBytesWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mgenericpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_arg_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'join'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\programdata\\anaconda3\\lib\\ntpath.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.path.join??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用walk获取指定目录下的所有文件名(包括完整路径)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;32mdef\u001b[0m \u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\"Directory tree generator.\n",
       "\n",
       "    For each directory in the directory tree rooted at top (including top\n",
       "    itself, but excluding '.' and '..'), yields a 3-tuple\n",
       "\n",
       "        dirpath, dirnames, filenames\n",
       "\n",
       "    dirpath is a string, the path to the directory.  dirnames is a list of\n",
       "    the names of the subdirectories in dirpath (excluding '.' and '..').\n",
       "    filenames is a list of the names of the non-directory files in dirpath.\n",
       "    Note that the names in the lists are just names, with no path components.\n",
       "    To get a full path (which begins with top) to a file or directory in\n",
       "    dirpath, do os.path.join(dirpath, name).\n",
       "\n",
       "    If optional arg 'topdown' is true or not specified, the triple for a\n",
       "    directory is generated before the triples for any of its subdirectories\n",
       "    (directories are generated top down).  If topdown is false, the triple\n",
       "    for a directory is generated after the triples for all of its\n",
       "    subdirectories (directories are generated bottom up).\n",
       "\n",
       "    When topdown is true, the caller can modify the dirnames list in-place\n",
       "    (e.g., via del or slice assignment), and walk will only recurse into the\n",
       "    subdirectories whose names remain in dirnames; this can be used to prune the\n",
       "    search, or to impose a specific order of visiting.  Modifying dirnames when\n",
       "    topdown is false is ineffective, since the directories in dirnames have\n",
       "    already been generated by the time dirnames itself is generated. No matter\n",
       "    the value of topdown, the list of subdirectories is retrieved before the\n",
       "    tuples for the directory and its subdirectories are generated.\n",
       "\n",
       "    By default errors from the os.scandir() call are ignored.  If\n",
       "    optional arg 'onerror' is specified, it should be a function; it\n",
       "    will be called with one argument, an OSError instance.  It can\n",
       "    report the error to continue with the walk, or raise the exception\n",
       "    to abort the walk.  Note that the filename is available as the\n",
       "    filename attribute of the exception object.\n",
       "\n",
       "    By default, os.walk does not follow symbolic links to subdirectories on\n",
       "    systems that support them.  In order to get this functionality, set the\n",
       "    optional argument 'followlinks' to true.\n",
       "\n",
       "    Caution:  if you pass a relative pathname for top, don't change the\n",
       "    current working directory between resumptions of walk.  walk never\n",
       "    changes the current directory, and assumes that the client doesn't\n",
       "    either.\n",
       "\n",
       "    Example:\n",
       "\n",
       "    import os\n",
       "    from os.path import join, getsize\n",
       "    for root, dirs, files in os.walk('python/Lib/email'):\n",
       "        print(root, \"consumes\", end=\"\")\n",
       "        print(sum([getsize(join(root, name)) for name in files]), end=\"\")\n",
       "        print(\"bytes in\", len(files), \"non-directory files\")\n",
       "        if 'CVS' in dirs:\n",
       "            dirs.remove('CVS')  # don't visit CVS directories\n",
       "\n",
       "    \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdirs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnondirs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwalk_dirs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# We may not have read permission for top, in which case we can't\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# get a list of the files the directory contains.  os.walk\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# always suppressed the exception then, rather than blow up for a\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# minor reason when (say) a thousand readable directories are still\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# left to visit.  That logic is copied here.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Note that scandir is global in this module due\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# to earlier import-*.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mscandir_it\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0monerror\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mwith\u001b[0m \u001b[0mscandir_it\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mentry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscandir_it\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;32mbreak\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0monerror\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mreturn\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mis_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# If is_dir() raises an OSError, consider that the entry is not\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# a directory, same behaviour than os.path.isdir().\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mis_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mis_dir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mdirs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mnondirs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtopdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_dir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# Bottom-up: recurse into sub-directory, but exclude symlinks to\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# directories if followlinks is False\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mwalk_into\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0mis_symlink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_symlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;31m# If is_symlink() raises an OSError, consider that the\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;31m# entry is not a symbolic link, same behaviour than\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[1;31m# os.path.islink().\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0mis_symlink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mwalk_into\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_symlink\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mwalk_into\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mwalk_dirs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# Yield before recursion if going top down\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32myield\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnondirs\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Recurse into sub-directories\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mislink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mnew_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# Issue #23605: os.path.islink() is used instead of caching\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# entry.is_symlink() result during the loop on os.scandir() because\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# the caller can replace the directory entry during the \"yield\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# above.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mfollowlinks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Recurse into sub-directories\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mnew_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwalk_dirs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopdown\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollowlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Yield after recursion if going bottom up\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32myield\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnondirs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\programdata\\anaconda3\\lib\\os.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.walk??\n",
    "# 返回值是个三元组:  dirpath, dirnames, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i D:\\Py\\note\n",
      "j ['.ipynb_checkpoints', 'data', 'python_cookbook', 'test315', 'test316', 'test316_1', 'test42', 'test719']\n",
      "k ['00-start.ipynb', '01-dict.ipynb', '01-list.ipynb', '01-set.ipynb', '01-string.ipynb', '01-tuple.ipynb', '04-for.ipynb', '04-if.ipynb', '04-while.ipynb', '05-function.ipynb', '10-class (2).ipynb', '11-OS.ipynb', '12-exceptions.ipynb', '13-testing.ipynb', '14-matplotlib.pyplot.ipynb', '14-pygal.ipynb', '20-file.ipynb', '21-pymssql-wenyin&xwlw&menjin.ipynb', '22-pymysql-mingyuan.ipynb', '23-sqlalchemy-mysql.ipynb', '30-re-regular_expressions.ipynb', '30-regex-ref.ipynb', '30-T&D wrangling.ipynb', '40-numpy.ipynb', '50-pandas.ipynb', '70-http.ipynb', '90-pygame-1.ipynb', 'datetime.ipynb', 'formula.xls', 'log.txt', 'style.xlsx', 'test11.xlsx', 'Untitled.ipynb', 'wrd_xwcs.ipynb', 'XY-ZY修订.ipynb', '副本材料科学与工程学院本科毕业生需办理离校手续清单.xlsx']\n",
      "i D:\\Py\\note\\.ipynb_checkpoints\n",
      "j []\n",
      "k ['00-start-checkpoint.ipynb', '01-dict-checkpoint.ipynb', '01-list-checkpoint.ipynb', '01-set-checkpoint.ipynb', '01-string-checkpoint.ipynb', '01-tuple-checkpoint.ipynb', '04-for-checkpoint.ipynb', '04-if-- (2)-checkpoint.ipynb', '04-if--.ipynb', '04-while-checkpoint.ipynb', '05-function-checkpoint.ipynb', '09-function-checkpoint.ipynb', '09-function.ipynb', '10-class (2)-checkpoint.ipynb', '10-class-checkpoint.ipynb', '10-class.ipynb', '11-OS-checkpoint.ipynb', '12-exceptions-checkpoint.ipynb', '13-testing-checkpoint.ipynb', '20-file-checkpoint.ipynb', '21-pymssql-wenyin&xwlw&menjin-checkpoint.ipynb', '22-pymysql-mingyuan-checkpoint.ipynb', '23-sqlalchemy-mysql-checkpoint.ipynb', '30-re-regular_expressions-checkpoint.ipynb', '30-regex-ref-checkpoint.ipynb', '30-T&D wrangling-checkpoint.ipynb', '40-numpy-checkpoint.ipynb', '50-pandas-checkpoint.ipynb', 'datetime-checkpoint.ipynb', 'Untitled-checkpoint.ipynb', 'wrd_xwcs-checkpoint.ipynb', 'XY-ZY修订-checkpoint.ipynb']\n",
      "i D:\\Py\\note\\data\n",
      "j []\n",
      "k ['csv1.csv', 'pandas-1.0.1.pdf', 'programming.txt', 'test.txt', 'test1.txt', 'test2.txt']\n",
      "i D:\\Py\\note\\python_cookbook\n",
      "j ['.ipynb_checkpoints']\n",
      "k ['01-Data Structures and Algorithms.ipynb']\n",
      "i D:\\Py\\note\\python_cookbook\\.ipynb_checkpoints\n",
      "j []\n",
      "k ['01-Data Structures and Algorithms-checkpoint.ipynb']\n",
      "i D:\\Py\\note\\test315\n",
      "j []\n",
      "k []\n",
      "i D:\\Py\\note\\test316\n",
      "j []\n",
      "k []\n",
      "i D:\\Py\\note\\test316_1\n",
      "j []\n",
      "k []\n",
      "i D:\\Py\\note\\test42\n",
      "j []\n",
      "k []\n",
      "i D:\\Py\\note\\test719\n",
      "j []\n",
      "k []\n"
     ]
    }
   ],
   "source": [
    "for i,j,k in os.walk(r'D:\\Py\\note'):\n",
    "    print(\"i\",i)\n",
    "    print(\"j\",j)\n",
    "    print(\"k\",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取指定目录下所有文件de,返回为list\n",
    "def dirfiles(infilepath):\n",
    "    lst = []\n",
    "    for dirpath, dirnames, filenames in os.walk(infilepath):\n",
    "        for file in filenames:\n",
    "            fullpath = os.path.join(dirpath, file)\n",
    "            lst.append(fullpath)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dirfiles(r'D:\\Py\\note'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\00-start.ipynb',\n",
       " '.\\\\01-dict.ipynb',\n",
       " '.\\\\01-list.ipynb',\n",
       " '.\\\\01-set.ipynb',\n",
       " '.\\\\01-string.ipynb',\n",
       " '.\\\\01-tuple.ipynb',\n",
       " '.\\\\04-for.ipynb',\n",
       " '.\\\\04-if.ipynb',\n",
       " '.\\\\04-while.ipynb',\n",
       " '.\\\\05-function.ipynb',\n",
       " '.\\\\10-class (2).ipynb',\n",
       " '.\\\\11-OS.ipynb',\n",
       " '.\\\\12-exceptions.ipynb',\n",
       " '.\\\\13-testing.ipynb',\n",
       " '.\\\\14-matplotlib.pyplot.ipynb',\n",
       " '.\\\\14-pygal.ipynb',\n",
       " '.\\\\20-file.ipynb',\n",
       " '.\\\\21-pymssql-wenyin&xwlw&menjin.ipynb',\n",
       " '.\\\\22-pymysql-mingyuan.ipynb',\n",
       " '.\\\\23-sqlalchemy-mysql.ipynb',\n",
       " '.\\\\30-re-regular_expressions.ipynb',\n",
       " '.\\\\30-regex-ref.ipynb',\n",
       " '.\\\\30-T&D wrangling.ipynb',\n",
       " '.\\\\40-numpy.ipynb',\n",
       " '.\\\\50-pandas.ipynb',\n",
       " '.\\\\70-http.ipynb',\n",
       " '.\\\\90-pygame-1.ipynb',\n",
       " '.\\\\datetime.ipynb',\n",
       " '.\\\\formula.xls',\n",
       " '.\\\\log.txt',\n",
       " '.\\\\style.xlsx',\n",
       " '.\\\\test11.xlsx',\n",
       " '.\\\\Untitled.ipynb',\n",
       " '.\\\\wrd_xwcs.ipynb',\n",
       " '.\\\\XY-ZY修订.ipynb',\n",
       " '.\\\\副本材料科学与工程学院本科毕业生需办理离校手续清单.xlsx',\n",
       " '.\\\\.ipynb_checkpoints\\\\00-start-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\01-dict-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\01-list-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\01-set-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\01-string-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\01-tuple-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\04-for-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\04-if-- (2)-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\04-if--.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\04-while-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\05-function-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\09-function-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\09-function.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\10-class (2)-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\10-class-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\10-class.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\11-OS-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\12-exceptions-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\13-testing-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\20-file-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\21-pymssql-wenyin&xwlw&menjin-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\22-pymysql-mingyuan-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\23-sqlalchemy-mysql-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\30-re-regular_expressions-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\30-regex-ref-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\30-T&D wrangling-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\40-numpy-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\50-pandas-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\datetime-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\Untitled-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\wrd_xwcs-checkpoint.ipynb',\n",
       " '.\\\\.ipynb_checkpoints\\\\XY-ZY修订-checkpoint.ipynb',\n",
       " '.\\\\data\\\\csv1.csv',\n",
       " '.\\\\data\\\\pandas-1.0.1.pdf',\n",
       " '.\\\\data\\\\programming.txt',\n",
       " '.\\\\data\\\\test.txt',\n",
       " '.\\\\data\\\\test1.txt',\n",
       " '.\\\\data\\\\test2.txt',\n",
       " '.\\\\python_cookbook\\\\01-Data Structures and Algorithms.ipynb',\n",
       " '.\\\\python_cookbook\\\\.ipynb_checkpoints\\\\01-Data Structures and Algorithms-checkpoint.ipynb']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirfiles('.')\n",
    "# . 表示当前路径, 由于传入的是相对路径, 返回的list 也是相对路径下的文件列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看文件大小\n",
    "* os.path.getsize()查看传入的文件的字节数   \n",
    "    如果传入目录,并不会返回目录下所有文件的总大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(r'D:\\Py\\note\\log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(r'D:\\Py\\note')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2859749"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(r'D:\\Py\\note\\30-T&D wrangling.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结合listdir命令,可以查看给定路径下的所有文件的总大小\n",
    "def gettotalsize(filepath):\n",
    "    files = os.listdir(filepath)\n",
    "    totalsize = 0\n",
    "    for file in files:\n",
    "        totalsize = totalsize + os.path.getsize(file)\n",
    "    return totalsize,len(files),files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5770221,\n",
       " 44,\n",
       " ['.ipynb_checkpoints',\n",
       "  '00-start.ipynb',\n",
       "  '01-dict.ipynb',\n",
       "  '01-list.ipynb',\n",
       "  '01-set.ipynb',\n",
       "  '01-string.ipynb',\n",
       "  '01-tuple.ipynb',\n",
       "  '04-for.ipynb',\n",
       "  '04-if.ipynb',\n",
       "  '04-while.ipynb',\n",
       "  '05-function.ipynb',\n",
       "  '10-class (2).ipynb',\n",
       "  '11-OS.ipynb',\n",
       "  '12-exceptions.ipynb',\n",
       "  '13-testing.ipynb',\n",
       "  '14-matplotlib.pyplot.ipynb',\n",
       "  '14-pygal.ipynb',\n",
       "  '20-file.ipynb',\n",
       "  '21-pymssql-wenyin&xwlw&menjin.ipynb',\n",
       "  '22-pymysql-mingyuan.ipynb',\n",
       "  '23-sqlalchemy-mysql.ipynb',\n",
       "  '30-re-regular_expressions.ipynb',\n",
       "  '30-regex-ref.ipynb',\n",
       "  '30-T&D wrangling.ipynb',\n",
       "  '40-numpy.ipynb',\n",
       "  '50-pandas.ipynb',\n",
       "  '70-http.ipynb',\n",
       "  '90-pygame-1.ipynb',\n",
       "  'data',\n",
       "  'datetime.ipynb',\n",
       "  'formula.xls',\n",
       "  'log.txt',\n",
       "  'python_cookbook',\n",
       "  'style.xlsx',\n",
       "  'test11.xlsx',\n",
       "  'test315',\n",
       "  'test316',\n",
       "  'test316_1',\n",
       "  'test42',\n",
       "  'test719',\n",
       "  'Untitled.ipynb',\n",
       "  'wrd_xwcs.ipynb',\n",
       "  'XY-ZY修订.ipynb',\n",
       "  '副本材料科学与工程学院本科毕业生需办理离校手续清单.xlsx'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gettotalsize(filepath = r'D:\\Py\\note')\n",
    "# 检查发现,只返回了给定目录下的文件大小,而没包括子文件夹内的文件大小\n",
    "# 需要用递归或者使用 os.walk 来获取目录下所有文件(包括各级子文件)下的文件大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改进\n",
    "# 结合listdir命令,可以查看给定路径下的所有文件的总大小\n",
    "def gettotalsize(filepath):\n",
    "    files = os.listdir(filepath)\n",
    "    filenum=len(files)\n",
    "    totalsize = 0\n",
    "    for file in files:\n",
    "        if os.path.isdir(file):\n",
    "            totalsize = totalsize + gettotalsize(file)[0]\n",
    "            filenum = filenum-1 + gettotalsize(file)[1]\n",
    "            files.remove(file)\n",
    "            files.extend(gettotalsize(file)[2])\n",
    "        if os.path.isfile(file):\n",
    "            totalsize = totalsize + os.path.getsize(file)\n",
    "    return totalsize,len(files),files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5430348,\n",
       " 109,\n",
       " ['00-start.ipynb',\n",
       "  '01-dict.ipynb',\n",
       "  '01-list.ipynb',\n",
       "  '01-set.ipynb',\n",
       "  '01-string.ipynb',\n",
       "  '01-tuple.ipynb',\n",
       "  '04-for.ipynb',\n",
       "  '04-if.ipynb',\n",
       "  '04-while.ipynb',\n",
       "  '05-function.ipynb',\n",
       "  '10-class (2).ipynb',\n",
       "  '11-OS.ipynb',\n",
       "  '12-exceptions.ipynb',\n",
       "  '13-testing.ipynb',\n",
       "  '14-matplotlib.pyplot.ipynb',\n",
       "  '14-pygal.ipynb',\n",
       "  '20-file.ipynb',\n",
       "  '21-pymssql-wenyin&xwlw&menjin.ipynb',\n",
       "  '22-pymysql-mingyuan.ipynb',\n",
       "  '23-sqlalchemy-mysql.ipynb',\n",
       "  '30-re-regular_expressions.ipynb',\n",
       "  '30-regex-ref.ipynb',\n",
       "  '30-T&D wrangling.ipynb',\n",
       "  '40-numpy.ipynb',\n",
       "  '50-pandas.ipynb',\n",
       "  '70-http.ipynb',\n",
       "  '90-pygame-1.ipynb',\n",
       "  'datetime.ipynb',\n",
       "  'formula.xls',\n",
       "  'log.txt',\n",
       "  'style.xlsx',\n",
       "  'test11.xlsx',\n",
       "  'test316',\n",
       "  'test42',\n",
       "  'Untitled.ipynb',\n",
       "  'wrd_xwcs.ipynb',\n",
       "  'XY-ZY修订.ipynb',\n",
       "  '副本材料科学与工程学院本科毕业生需办理离校手续清单.xlsx',\n",
       "  '00-start-checkpoint.ipynb',\n",
       "  '01-dict-checkpoint.ipynb',\n",
       "  '01-list-checkpoint.ipynb',\n",
       "  '01-set-checkpoint.ipynb',\n",
       "  '01-string-checkpoint.ipynb',\n",
       "  '01-tuple-checkpoint.ipynb',\n",
       "  '04-for-checkpoint.ipynb',\n",
       "  '04-if-- (2)-checkpoint.ipynb',\n",
       "  '04-if--.ipynb',\n",
       "  '04-while-checkpoint.ipynb',\n",
       "  '05-function-checkpoint.ipynb',\n",
       "  '09-function-checkpoint.ipynb',\n",
       "  '09-function.ipynb',\n",
       "  '10-class (2)-checkpoint.ipynb',\n",
       "  '10-class-checkpoint.ipynb',\n",
       "  '10-class.ipynb',\n",
       "  '11-OS-checkpoint.ipynb',\n",
       "  '12-exceptions-checkpoint.ipynb',\n",
       "  '13-testing-checkpoint.ipynb',\n",
       "  '20-file-checkpoint.ipynb',\n",
       "  '21-pymssql-wenyin&xwlw&menjin-checkpoint.ipynb',\n",
       "  '22-pymysql-mingyuan-checkpoint.ipynb',\n",
       "  '23-sqlalchemy-mysql-checkpoint.ipynb',\n",
       "  '30-re-regular_expressions-checkpoint.ipynb',\n",
       "  '30-regex-ref-checkpoint.ipynb',\n",
       "  '30-T&D wrangling-checkpoint.ipynb',\n",
       "  '40-numpy-checkpoint.ipynb',\n",
       "  '50-pandas-checkpoint.ipynb',\n",
       "  'datetime-checkpoint.ipynb',\n",
       "  'Untitled-checkpoint.ipynb',\n",
       "  'wrd_xwcs-checkpoint.ipynb',\n",
       "  'XY-ZY修订-checkpoint.ipynb',\n",
       "  'csv1.csv',\n",
       "  'pandas-1.0.1.pdf',\n",
       "  'programming.txt',\n",
       "  'test.txt',\n",
       "  'test1.txt',\n",
       "  'test2.txt',\n",
       "  '01-Data Structures and Algorithms.ipynb',\n",
       "  '00-start-checkpoint.ipynb',\n",
       "  '01-dict-checkpoint.ipynb',\n",
       "  '01-list-checkpoint.ipynb',\n",
       "  '01-set-checkpoint.ipynb',\n",
       "  '01-string-checkpoint.ipynb',\n",
       "  '01-tuple-checkpoint.ipynb',\n",
       "  '04-for-checkpoint.ipynb',\n",
       "  '04-if-- (2)-checkpoint.ipynb',\n",
       "  '04-if--.ipynb',\n",
       "  '04-while-checkpoint.ipynb',\n",
       "  '05-function-checkpoint.ipynb',\n",
       "  '09-function-checkpoint.ipynb',\n",
       "  '09-function.ipynb',\n",
       "  '10-class (2)-checkpoint.ipynb',\n",
       "  '10-class-checkpoint.ipynb',\n",
       "  '10-class.ipynb',\n",
       "  '11-OS-checkpoint.ipynb',\n",
       "  '12-exceptions-checkpoint.ipynb',\n",
       "  '13-testing-checkpoint.ipynb',\n",
       "  '20-file-checkpoint.ipynb',\n",
       "  '21-pymssql-wenyin&xwlw&menjin-checkpoint.ipynb',\n",
       "  '22-pymysql-mingyuan-checkpoint.ipynb',\n",
       "  '23-sqlalchemy-mysql-checkpoint.ipynb',\n",
       "  '30-re-regular_expressions-checkpoint.ipynb',\n",
       "  '30-regex-ref-checkpoint.ipynb',\n",
       "  '30-T&D wrangling-checkpoint.ipynb',\n",
       "  '40-numpy-checkpoint.ipynb',\n",
       "  '50-pandas-checkpoint.ipynb',\n",
       "  'datetime-checkpoint.ipynb',\n",
       "  'Untitled-checkpoint.ipynb',\n",
       "  'wrd_xwcs-checkpoint.ipynb',\n",
       "  'XY-ZY修订-checkpoint.ipynb'])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gettotalsize(filepath = r'D:\\Py\\note')#[:2]\n",
    "# 文件列表, 文件个数多了一个,但是文件总大小为什么还是不对?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复用walk方法获取文件列表的方法,计算文件夹下的总文件大小\n",
    "def gettotalsizebywalk(path):\n",
    "    filelist=dirfiles(path)\n",
    "    totalsize=0\n",
    "    for file in filelist:\n",
    "        totalsize = totalsize + os.path.getsize(file)\n",
    "    return totalsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22081162"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gettotalsizebywalk(path = r'D:\\Py\\note')#[:2]\n",
    "# 这次就对了.\n",
    "# 之前的函数,应该先构造文件列表,然后再分别获取文件列表里的文件大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改进 #　进一步改进\n",
    "# 结合listdir命令,可以查看给定路径下的所有文件的总大小\n",
    "def gettotalsize(filepath):\n",
    "    files = os.listdir(filepath)\n",
    "    filenum=len(files)\n",
    "    totalsize = 0\n",
    "    for file in files:\n",
    "        if os.path.isdir(file):\n",
    "            filenum = filenum-1 + gettotalsize(file)[1]\n",
    "            files.remove(file)\n",
    "            files.extend(gettotalsize(file)[2])\n",
    "    for file in files:\n",
    "        if os.path.isfile(file):\n",
    "            totalsize = totalsize + os.path.getsize(file)\n",
    "    return totalsize,len(files),files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5753837,\n",
       " 109,\n",
       " ['00-start.ipynb',\n",
       "  '01-dict.ipynb',\n",
       "  '01-list.ipynb',\n",
       "  '01-set.ipynb',\n",
       "  '01-string.ipynb',\n",
       "  '01-tuple.ipynb',\n",
       "  '04-for.ipynb',\n",
       "  '04-if.ipynb',\n",
       "  '04-while.ipynb',\n",
       "  '05-function.ipynb',\n",
       "  '10-class (2).ipynb',\n",
       "  '11-OS.ipynb',\n",
       "  '12-exceptions.ipynb',\n",
       "  '13-testing.ipynb',\n",
       "  '14-matplotlib.pyplot.ipynb',\n",
       "  '14-pygal.ipynb',\n",
       "  '20-file.ipynb',\n",
       "  '21-pymssql-wenyin&xwlw&menjin.ipynb',\n",
       "  '22-pymysql-mingyuan.ipynb',\n",
       "  '23-sqlalchemy-mysql.ipynb',\n",
       "  '30-re-regular_expressions.ipynb',\n",
       "  '30-regex-ref.ipynb',\n",
       "  '30-T&D wrangling.ipynb',\n",
       "  '40-numpy.ipynb',\n",
       "  '50-pandas.ipynb',\n",
       "  '70-http.ipynb',\n",
       "  '90-pygame-1.ipynb',\n",
       "  'datetime.ipynb',\n",
       "  'formula.xls',\n",
       "  'log.txt',\n",
       "  'style.xlsx',\n",
       "  'test11.xlsx',\n",
       "  'test316',\n",
       "  'test42',\n",
       "  'Untitled.ipynb',\n",
       "  'wrd_xwcs.ipynb',\n",
       "  'XY-ZY修订.ipynb',\n",
       "  '副本材料科学与工程学院本科毕业生需办理离校手续清单.xlsx',\n",
       "  '00-start-checkpoint.ipynb',\n",
       "  '01-dict-checkpoint.ipynb',\n",
       "  '01-list-checkpoint.ipynb',\n",
       "  '01-set-checkpoint.ipynb',\n",
       "  '01-string-checkpoint.ipynb',\n",
       "  '01-tuple-checkpoint.ipynb',\n",
       "  '04-for-checkpoint.ipynb',\n",
       "  '04-if-- (2)-checkpoint.ipynb',\n",
       "  '04-if--.ipynb',\n",
       "  '04-while-checkpoint.ipynb',\n",
       "  '05-function-checkpoint.ipynb',\n",
       "  '09-function-checkpoint.ipynb',\n",
       "  '09-function.ipynb',\n",
       "  '10-class (2)-checkpoint.ipynb',\n",
       "  '10-class-checkpoint.ipynb',\n",
       "  '10-class.ipynb',\n",
       "  '11-OS-checkpoint.ipynb',\n",
       "  '12-exceptions-checkpoint.ipynb',\n",
       "  '13-testing-checkpoint.ipynb',\n",
       "  '20-file-checkpoint.ipynb',\n",
       "  '21-pymssql-wenyin&xwlw&menjin-checkpoint.ipynb',\n",
       "  '22-pymysql-mingyuan-checkpoint.ipynb',\n",
       "  '23-sqlalchemy-mysql-checkpoint.ipynb',\n",
       "  '30-re-regular_expressions-checkpoint.ipynb',\n",
       "  '30-regex-ref-checkpoint.ipynb',\n",
       "  '30-T&D wrangling-checkpoint.ipynb',\n",
       "  '40-numpy-checkpoint.ipynb',\n",
       "  '50-pandas-checkpoint.ipynb',\n",
       "  'datetime-checkpoint.ipynb',\n",
       "  'Untitled-checkpoint.ipynb',\n",
       "  'wrd_xwcs-checkpoint.ipynb',\n",
       "  'XY-ZY修订-checkpoint.ipynb',\n",
       "  'csv1.csv',\n",
       "  'pandas-1.0.1.pdf',\n",
       "  'programming.txt',\n",
       "  'test.txt',\n",
       "  'test1.txt',\n",
       "  'test2.txt',\n",
       "  '01-Data Structures and Algorithms.ipynb',\n",
       "  '00-start-checkpoint.ipynb',\n",
       "  '01-dict-checkpoint.ipynb',\n",
       "  '01-list-checkpoint.ipynb',\n",
       "  '01-set-checkpoint.ipynb',\n",
       "  '01-string-checkpoint.ipynb',\n",
       "  '01-tuple-checkpoint.ipynb',\n",
       "  '04-for-checkpoint.ipynb',\n",
       "  '04-if-- (2)-checkpoint.ipynb',\n",
       "  '04-if--.ipynb',\n",
       "  '04-while-checkpoint.ipynb',\n",
       "  '05-function-checkpoint.ipynb',\n",
       "  '09-function-checkpoint.ipynb',\n",
       "  '09-function.ipynb',\n",
       "  '10-class (2)-checkpoint.ipynb',\n",
       "  '10-class-checkpoint.ipynb',\n",
       "  '10-class.ipynb',\n",
       "  '11-OS-checkpoint.ipynb',\n",
       "  '12-exceptions-checkpoint.ipynb',\n",
       "  '13-testing-checkpoint.ipynb',\n",
       "  '20-file-checkpoint.ipynb',\n",
       "  '21-pymssql-wenyin&xwlw&menjin-checkpoint.ipynb',\n",
       "  '22-pymysql-mingyuan-checkpoint.ipynb',\n",
       "  '23-sqlalchemy-mysql-checkpoint.ipynb',\n",
       "  '30-re-regular_expressions-checkpoint.ipynb',\n",
       "  '30-regex-ref-checkpoint.ipynb',\n",
       "  '30-T&D wrangling-checkpoint.ipynb',\n",
       "  '40-numpy-checkpoint.ipynb',\n",
       "  '50-pandas-checkpoint.ipynb',\n",
       "  'datetime-checkpoint.ipynb',\n",
       "  'Untitled-checkpoint.ipynb',\n",
       "  'wrd_xwcs-checkpoint.ipynb',\n",
       "  'XY-ZY修订-checkpoint.ipynb'])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gettotalsize(filepath = r'D:\\Py\\note')#[:2]\n",
    "# 可能是因为路径的问题,如果能获取到绝对路径,应该可以解决总文件大小不对的问题."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相对路径简介   \n",
    "  * 绝对路径是从根文件夹开始,直到文件所在的文件夹的路径表示法,例如:  'C:\\Program Files\\Internet Explorer'表示C盘的ie 浏览器所在的路径\n",
    "  * 相对路径是从当前工作目录算起,直到文件所在的文件夹的路径表示法.例如: '.\\data' 表示当前工作目录下的data文件夹\n",
    "     * 相对路径中的单个的点('.')表示\"这个文件夹\",就是当前工作目录.\n",
    "       例如: '.\\' 表示当前工作目录,上述的 '.\\data'表示当前工作目录下的data文件夹\n",
    "     * 如果要表示父文件夹,使用 '..'.\n",
    "       例如,当前工作目录的父文件夹为'..',父文件夹的父文件夹为'..\\..'\n",
    "  os.path.abspath()函数可以给出已知相对路径的绝对路径.接下来我们用该函数验证一下上述的内容."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Py'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当前工作目录的父文件夹的绝对路径\n",
    "os.path.abspath('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-91-93ba529c2331>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-91-93ba529c2331>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    os.path.abspath('..\\')\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# 当前工作目录的父文件夹的绝对路径\n",
    "os.path.abspath('..\\')\n",
    "# 最后不能加多余的\\,否则会报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* os.path.abspath 返回绝对路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当前工作目录的父文件夹的父文件夹的绝对路径\n",
    "# 已经是根目录了\n",
    "os.path.abspath('..\\..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再往上求根目录,还是最终的根目录\n",
    "os.path.abspath('..\\..\\..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Py\\\\note'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用os.path.abspath() 函数给出当前工作目录的绝对路径\n",
    "# '.'是相对路径表示法,表示当前工作目录\n",
    "os.path.abspath('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算相对路径\n",
    "* os.path.relpath(path,start) 函数可以计算出从start路径出发,到达path路径的相对路径表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\..\\\\..\\\\Program Files\\\\Internet Explorer'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例如,从\"C:\\Users\\Administrator\\Links\"到 刚刚提到的 ie 浏览器的相对路径表示\n",
    "os.path.relpath(r'C:\\Program Files\\Internet Explorer',r'C:\\Users\\Administrator\\Links')\n",
    "# 如果不在同一个分区,则会报错\n",
    "# ValueError: path is on mount 'C:', start on mount 'D:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\..\\\\ProgramData\\\\Anaconda3'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start可以使用相对路径,例如:计算当前目录('.')到anaconda3所在文件夹的相对路径\n",
    "os.path.relpath(r'D:\\ProgramData\\Anaconda3','.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "path is on mount 'C:', start on mount 'd:'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-44ba20d8facb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 例如,求当前目录(D盘)到 ie 浏览器的相对路径\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# ValueError: path is on mount 'C:', start on mount 'D:'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Program Files\\Internet Explorer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\ntpath.py\u001b[0m in \u001b[0;36mrelpath\u001b[1;34m(path, start)\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnormcase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_drive\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnormcase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_drive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             raise ValueError(\"path is on mount %r, start on mount %r\" % (\n\u001b[1;32m--> 562\u001b[1;33m                 path_drive, start_drive))\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[0mstart_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstart_rest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: path is on mount 'C:', start on mount 'd:'"
     ]
    }
   ],
   "source": [
    "# 但如果两个目录不在同一个分区,则会报错\n",
    "# 例如,求当前目录(D盘)到 ie 浏览器的相对路径\n",
    "# ValueError: path is on mount 'C:', start on mount 'D:'\n",
    "os.path.relpath(r'C:\\Program Files\\Internet Explorer','.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;32mdef\u001b[0m \u001b[0mrelpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\"Return a relative version of a path\"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb'\\\\'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcurdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb'.'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mpardir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb'..'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcurdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mpardir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'..'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurdir\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no path specified\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mstart_abs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mpath_abs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mstart_drive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_rest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitdrive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_abs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mpath_drive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_rest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitdrive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_abs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mnormcase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_drive\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnormcase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_drive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"path is on mount %r, start on mount %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mpath_drive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_drive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mstart_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstart_rest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mpath_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpath_rest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Work out how much of the filepath is shared by start and path.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mnormcase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnormcase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mbreak\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mrel_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpardir\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpath_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrel_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mcurdir\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mrel_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBytesWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mgenericpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_arg_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relpath'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\programdata\\anaconda3\\lib\\ntpath.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.path.relpath??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os 模块还有很多其他功能, 特别是针对不同操作系统及文件系统, 做了很多特殊处理, 由于暂时还不会接触更多这方面的内容, 暂不进行更进一步的学习.   \n",
    "以下仅仅列举几个非常基本的操作系统相关的方法."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看当前电脑相关信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt\n"
     ]
    }
   ],
   "source": [
    "#查看操作系统\n",
    "print(os.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environ({'ALLUSERSPROFILE': 'C:\\\\ProgramData', 'APPDATA': 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Roaming', 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files', 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files', 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files', 'COMPUTERNAME': 'PC-201301150725', 'COMSPEC': 'C:\\\\Windows\\\\system32\\\\cmd.exe', 'CONDA_DEFAULT_ENV': 'base', 'CONDA_EXE': 'd:\\\\ProgramData\\\\Anaconda3\\\\Scripts\\\\conda.exe', 'CONDA_PREFIX': 'd:\\\\ProgramData\\\\Anaconda3', 'CONDA_PROMPT_MODIFIER': '(base) ', 'CONDA_PYTHON_EXE': 'd:\\\\ProgramData\\\\Anaconda3\\\\python.exe', 'CONDA_SHLVL': '1', 'CUDA_PATH': 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.0', 'CUDA_PATH_V10_0': 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.0', 'DEVMGR_SHOW_DETAILS': '1', 'FP_NO_HOST_CHECK': 'NO', 'HOMEDRIVE': 'C:', 'HOMEPATH': '\\\\Users\\\\Administrator', 'LOCALAPPDATA': 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Local', 'LOGONSERVER': '\\\\\\\\PC-201301150725', 'NUMBER_OF_PROCESSORS': '4', 'NVCUDASAMPLES10_0_ROOT': 'C:\\\\ProgramData\\\\NVIDIA Corporation\\\\CUDA Samples\\\\v10.0', 'NVCUDASAMPLES_ROOT': 'C:\\\\ProgramData\\\\NVIDIA Corporation\\\\CUDA Samples\\\\v10.0', 'NVTOOLSEXT_PATH': 'C:\\\\Program Files\\\\NVIDIA Corporation\\\\NvToolsExt\\\\', 'OS': 'Windows_NT', 'PATH': 'd:\\\\ProgramData\\\\Anaconda3;d:\\\\ProgramData\\\\Anaconda3\\\\Library\\\\mingw-w64\\\\bin;d:\\\\ProgramData\\\\Anaconda3\\\\Library\\\\usr\\\\bin;d:\\\\ProgramData\\\\Anaconda3\\\\Library\\\\bin;d:\\\\ProgramData\\\\Anaconda3\\\\Scripts;d:\\\\ProgramData\\\\Anaconda3\\\\bin;d:\\\\ProgramData\\\\Anaconda3\\\\condabin;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.0\\\\bin;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.0\\\\libnvvp;c:\\\\app\\\\Administrator\\\\product\\\\11.2.0\\\\client_1;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;.;C:\\\\Users\\\\Administrator\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.0\\\\lib\\\\x64', 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC', 'PROCESSOR_ARCHITECTURE': 'AMD64', 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 60 Stepping 3, GenuineIntel', 'PROCESSOR_LEVEL': '6', 'PROCESSOR_REVISION': '3c03', 'PROGRAMDATA': 'C:\\\\ProgramData', 'PROGRAMFILES': 'C:\\\\Program Files', 'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)', 'PROGRAMW6432': 'C:\\\\Program Files', 'PROMPT': '(base) $P$G', 'PSMODULEPATH': 'C:\\\\Windows\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules\\\\', 'PUBLIC': 'C:\\\\Users\\\\Public', 'SESSIONNAME': 'Console', 'SYSTEMDRIVE': 'C:', 'SYSTEMROOT': 'C:\\\\Windows', 'TEMP': 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp', 'TMP': 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp', 'USERDOMAIN': 'PC-201301150725', 'USERNAME': 'Administrator', 'USERPROFILE': 'C:\\\\Users\\\\Administrator', 'WINDIR': 'C:\\\\Windows', 'WINDOWS_TRACING_FLAGS': '3', 'WINDOWS_TRACING_LOGFILE': 'C:\\\\BVTBin\\\\Tests\\\\installpackage\\\\csilogfile.log', 'KERNEL_LAUNCH_TIMEOUT': '40', 'JPY_INTERRUPT_EVENT': '3424', 'IPY_INTERRUPT_EVENT': '3424', 'JPY_PARENT_PID': '3428', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline'})\n"
     ]
    }
   ],
   "source": [
    "#获取操作系统的所有环境变量\n",
    "print(os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6DC7933', 'aaRemove.exe', 'addins', 'amlog', 'ampa.exe', 'ampa.ini', 'AppCompat', 'AppPatch', 'assembly', 'bfsvc.exe', 'BitLockerDiscoveryVolumeContents', 'Boot', 'bootstat.dat', 'Branding', 'CSC', 'Cursors', 'D8Ecap.exe', 'debug', 'diagnostics', 'DigitalLocker', 'Downloaded Program Files', 'en-US', 'explorer.exe', 'Fonts', 'fveupdate.exe', 'Globalization', 'Help', 'HelpPane.exe', 'hh.exe', 'IME', 'inf', 'Installer', 'ISTask.dll', 'L2Schemas', 'LiveKernelReports', 'Logs', 'Media', 'mib.bin', 'Microsoft.NET', 'Migration', 'ModemLogs', 'msdfmap.ini', 'notepad.exe', 'NvContainerRecovery.bat', 'Offline Web Pages', 'panther', 'pc', 'Performance', 'PFRO.log', 'PLA', 'PolicyDefinitions', 'Prefetch', 'psnetwork.ini', 'regedit.exe', 'Registration', 'RemotePackages', 'rescache', 'Resources', 'ScData', 'SchCache', 'schemas', 'security', 'ServiceProfiles', 'servicing', 'Setup', 'setupact.log', 'setuperr.log', 'SoftwareDistribution', 'splwow64.exe', 'Starter.xml', 'system', 'system.ini', 'System32', 'SysWOW64', 'TAPI', 'Tasks', 'Temp', 'tracing', 'twain.dll', 'twain_32', 'twain_32.dll', 'twunk_16.exe', 'twunk_32.exe', 'Ultimate.xml', 'Vss', 'Web', 'win.ini', 'WindowsShell.Manifest', 'WindowsUpdate.log', 'winhlp32.exe', 'winsxs', 'WMSysPr9.prx', 'write.exe', 'wxb', 'zh-CN', '~GLC0000.TMP', '~GLC0001.TMP', '~GLH0000.TMP', '~GLH0001.TMP']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('c:\\\\windows')) #注意用的是双斜杠,也可以用反斜杠\n",
    "#获取指定路径下的所有文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## os模块的其他方法[待补充]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DirEntry', 'F_OK', 'MutableMapping', 'O_APPEND', 'O_BINARY', 'O_CREAT', 'O_EXCL', 'O_NOINHERIT', 'O_RANDOM', 'O_RDONLY', 'O_RDWR', 'O_SEQUENTIAL', 'O_SHORT_LIVED', 'O_TEMPORARY', 'O_TEXT', 'O_TRUNC', 'O_WRONLY', 'P_DETACH', 'P_NOWAIT', 'P_NOWAITO', 'P_OVERLAY', 'P_WAIT', 'PathLike', 'R_OK', 'SEEK_CUR', 'SEEK_END', 'SEEK_SET', 'TMP_MAX', 'W_OK', 'X_OK', '_Environ', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_check_methods', '_execvpe', '_exists', '_exit', '_fspath', '_get_exports_list', '_putenv', '_unsetenv', '_wrap_close', 'abc', 'abort', 'access', 'altsep', 'chdir', 'chmod', 'close', 'closerange', 'cpu_count', 'curdir', 'defpath', 'device_encoding', 'devnull', 'dup', 'dup2', 'environ', 'error', 'execl', 'execle', 'execlp', 'execlpe', 'execv', 'execve', 'execvp', 'execvpe', 'extsep', 'fdopen', 'fsdecode', 'fsencode', 'fspath', 'fstat', 'fsync', 'ftruncate', 'get_exec_path', 'get_handle_inheritable', 'get_inheritable', 'get_terminal_size', 'getcwd', 'getcwdb', 'getenv', 'getlogin', 'getpid', 'getppid', 'isatty', 'kill', 'linesep', 'link', 'listdir', 'lseek', 'lstat', 'makedirs', 'mkdir', 'name', 'open', 'pardir', 'path', 'pathsep', 'pipe', 'popen', 'putenv', 'read', 'readlink', 'remove', 'removedirs', 'rename', 'renames', 'replace', 'rmdir', 'scandir', 'sep', 'set_handle_inheritable', 'set_inheritable', 'spawnl', 'spawnle', 'spawnv', 'spawnve', 'st', 'startfile', 'stat', 'stat_result', 'statvfs_result', 'strerror', 'supports_bytes_environ', 'supports_dir_fd', 'supports_effective_ids', 'supports_fd', 'supports_follow_symlinks', 'symlink', 'sys', 'system', 'terminal_size', 'times', 'times_result', 'truncate', 'umask', 'uname_result', 'unlink', 'urandom', 'utime', 'waitpid', 'walk', 'write']\n"
     ]
    }
   ],
   "source": [
    "print(dir(os))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Return a collection containing process timing information.\n",
       "\n",
       "The object returned behaves like a named tuple with these fields:\n",
       "  (utime, stime, cutime, cstime, elapsed_time)\n",
       "All fields are floating point numbers.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.times??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m Read from a file descriptor.  Returns a bytes object.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.read??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_dir_fd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst_dir_fd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Rename a file or directory.\n",
       "\n",
       "If either src_dir_fd or dst_dir_fd is not None, it should be a file\n",
       "  descriptor open to a directory, and the respective path string (src or dst)\n",
       "  should be relative; the path will then be relative to that directory.\n",
       "src_dir_fd and dst_dir_fd, may not be implemented on your platform.\n",
       "  If they are unavailable, using them will raise a NotImplementedError.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.rename??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#修改文件名或文件夹名\n",
    "os.rename('test111111','test315')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '00-start.ipynb',\n",
       " '01-string.ipynb',\n",
       " '02-list.ipynb',\n",
       " '02-set.ipynb',\n",
       " '02-tuple.ipynb',\n",
       " '03-dict.ipynb',\n",
       " '04-for.ipynb',\n",
       " '04-if.ipynb',\n",
       " '04-while.ipynb',\n",
       " '05-function.ipynb',\n",
       " '10-class (2).ipynb',\n",
       " '11-OS.ipynb',\n",
       " '12-exceptions.ipynb',\n",
       " '13-testing.ipynb',\n",
       " '14-matplotlib.pyplot.ipynb',\n",
       " '14-pygal.ipynb',\n",
       " '20-file.ipynb',\n",
       " '21-pymssql-wenyin&xwlw&menjin.ipynb',\n",
       " '22-pymysql-mingyuan.ipynb',\n",
       " '23-sqlalchemy-mysql.ipynb',\n",
       " '30-re-regular_expressions.ipynb',\n",
       " '30-regex-ref.ipynb',\n",
       " '30-T&D wrangling.ipynb',\n",
       " '40-numpy.ipynb',\n",
       " '50-pandas.ipynb',\n",
       " '70-http.ipynb',\n",
       " '90-pygame-1.ipynb',\n",
       " 'data',\n",
       " 'log.txt',\n",
       " 'test315',\n",
       " 'Untitled.ipynb',\n",
       " 'wrd_xwcs.ipynb',\n",
       " 'XY-ZY修订.ipynb']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir() # 默认列出当前目录下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Set the position of a file descriptor.  Return the new position.\n",
       "\n",
       "Return the new cursor position in number of bytes\n",
       "relative to the beginning of the file.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.lseek??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m Return a bytes object containing random bytes suitable for cryptographic use.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.urandom??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'b\\xe8Bp\\x08\\xe1\\xf1\\x7f0\\xa3\\xb2\\x00', 12, bytes)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#随机生成一个指定长度的bytes类型\n",
    "osurand=os.urandom(12)\n",
    "osurand,len(osurand),type(osurand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;32mdef\u001b[0m \u001b[0mexecl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\"execl(file, *args)\n",
       "\n",
       "    Execute the executable file with argument list args, replacing the\n",
       "    current process. \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mexecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\programdata\\anaconda3\\lib\\os.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.execl??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfdopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;32mdef\u001b[0m \u001b[0mfdopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"invalid fd type (%s, expected integer)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\programdata\\anaconda3\\lib\\os.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.fdopen??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Return the number of CPUs in the system; return None if indeterminable.\n",
       "\n",
       "This number is not equivalent to the number of CPUs the current process can\n",
       "use.  The number of usable CPUs can be obtained with\n",
       "``len(os.sched_getaffinity(0))``\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.cpu_count??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'sched_getaffinity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-021045da60c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msched_getaffinity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'os' has no attribute 'sched_getaffinity'"
     ]
    }
   ],
   "source": [
    "len(os.sched_getaffinity(0))\n",
    "#AttributeError: module 'os' has no attribute 'sched_getaffinity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Truncate a file, specified by path, to a specific length.\n",
       "\n",
       "On some platforms, path may also be specified as an open file descriptor.\n",
       "  If this functionality is unavailable, using it raises an exception.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.truncate??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "stat_float_times([newval]) -> oldval\n",
       "\n",
       "Determine whether os.[lf]stat represents time stamps as float objects.\n",
       "\n",
       "If value is True, future calls to stat() return floats; if it is False,\n",
       "future calls return ints.\n",
       "If value is omitted, return the current setting.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.stat_float_times??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m Write a bytes object to a file descriptor.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.write??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习:如何使用递归列出目录及所有子目录下的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirallfiles(path):\n",
    "    lst=[]\n",
    "    fileList = os.listdir(path)\n",
    "    for f in fileList:\n",
    "        if os.path.isdir(f):     \n",
    "            lst.extend(dirallfiles(f))                  \n",
    "        #elif os.path.isfile(f):  \n",
    "        else:\n",
    "            dirName=os.path.dirname(f)\n",
    "            baseName=os.path.basename(f)\n",
    "            lst.append(os.path.join(path,dirName,baseName))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirallfiles(r'd:\\Py') #还有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考 https://blog.csdn.net/san1156/article/details/77885995\n",
    "import os;  \n",
    "files = list();  \n",
    "def DirAll(pathName):  \n",
    "    if os.path.exists(pathName):  \n",
    "        fileList = os.listdir(pathName);  \n",
    "        for f in fileList:  \n",
    "            if f==\"$RECYCLE.BIN\" or f==\"System Volume Information\":  \n",
    "                continue;  \n",
    "            f=os.path.join(pathName,f);  \n",
    "            if os.path.isdir(f):     \n",
    "                DirAll(f);                  \n",
    "            else:  \n",
    "                dirName=os.path.dirname(f);  \n",
    "                baseName=os.path.basename(f);  \n",
    "                if dirName.endswith(os.sep):  \n",
    "                    files.append(dirName+baseName);  \n",
    "                else:  \n",
    "                    files.append(dirName+os.sep+baseName);  \n",
    "\n",
    "DirAll(\"D:\\\\2\\\\\");  \n",
    "for f in files:  \n",
    "    print f\n",
    "    # print f.decode('gbk').encode('utf-8');  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#列出'/test/test1/'目录下的所有文件或目录（包括子目录）\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "def print_files(path):\n",
    "    lsdir = os.listdir(path)\n",
    "    dirs = [i for i in lsdir if os.path.isdir(os.path.join(path, i))]    \n",
    "    if dirs:\n",
    "        for i in dirs:\n",
    "            pass\n",
    "            #print_files(os.path.join(path, i))\n",
    "    files = [i for i in lsdir if os.path.isfile(os.path.join(path,i))]\n",
    "    #for f in files:  #列出所有文件(包括子目录下的文件)\n",
    "    for f in dirs:    #列出所有目录(包括子目录下的目录)\n",
    "        sss = (os.path.join(path, f))\n",
    "        #if os.path.isdir(sss): #判断路径是否为目录\n",
    "        print (sss)  \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\.ipynb_checkpoints\n",
      ".\\data\n",
      ".\\test315\n"
     ]
    }
   ],
   "source": [
    "print_files('.')  #列出'/test/test1/'目录下的所有文件或目录（包括子目录）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--.ipynb_checkpoints\n",
      "00-start.ipynb\n",
      "01-string.ipynb\n",
      "02-list.ipynb\n",
      "02-set.ipynb\n",
      "02-tuple.ipynb\n",
      "03-dict.ipynb\n",
      "04-for.ipynb\n",
      "04-if.ipynb\n",
      "04-while.ipynb\n",
      "05-function.ipynb\n",
      "10-class (2).ipynb\n",
      "11-OS.ipynb\n",
      "12-exceptions.ipynb\n",
      "13-testing.ipynb\n",
      "14-matplotlib.pyplot.ipynb\n",
      "14-pygal.ipynb\n",
      "20-file.ipynb\n",
      "21-pymssql-wenyin&xwlw&menjin.ipynb\n",
      "22-pymysql-mingyuan.ipynb\n",
      "23-sqlalchemy-mysql.ipynb\n",
      "30-re-regular_expressions.ipynb\n",
      "30-regex-ref.ipynb\n",
      "30-T&D wrangling.ipynb\n",
      "40-numpy.ipynb\n",
      "50-pandas.ipynb\n",
      "70-http.ipynb\n",
      "90-pygame-1.ipynb\n",
      "--data\n",
      "log.txt\n",
      "--test315\n",
      "Untitled.ipynb\n",
      "wrd_xwcs.ipynb\n",
      "XY-ZY修订.ipynb\n"
     ]
    }
   ],
   "source": [
    "path=r'D:\\Python\\note'\n",
    "f_p=os.listdir(path)\n",
    "to_txt=[]\n",
    "for i in f_p:\n",
    "    if os.path.isfile(i):\n",
    "        print(i)\n",
    "        to_txt.append(i)\n",
    "    else :\n",
    "        print('--'+i)\n",
    "        f_p1=os.listdir(i)\n",
    "        for j in f_p1:\n",
    "            if os.path.isfile(j):\n",
    "                print(i+j)\n",
    "                to_txt.append('--'+j)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00-start.ipynb',\n",
       " '01-string.ipynb',\n",
       " '02-list.ipynb',\n",
       " '02-set.ipynb',\n",
       " '02-tuple.ipynb',\n",
       " '03-dict.ipynb',\n",
       " '04-for.ipynb',\n",
       " '04-if.ipynb',\n",
       " '04-while.ipynb',\n",
       " '05-function.ipynb',\n",
       " '10-class (2).ipynb',\n",
       " '11-OS.ipynb',\n",
       " '12-exceptions.ipynb',\n",
       " '13-testing.ipynb',\n",
       " '14-matplotlib.pyplot.ipynb',\n",
       " '14-pygal.ipynb',\n",
       " '20-file.ipynb',\n",
       " '21-pymssql-wenyin&xwlw&menjin.ipynb',\n",
       " '22-pymysql-mingyuan.ipynb',\n",
       " '23-sqlalchemy-mysql.ipynb',\n",
       " '30-re-regular_expressions.ipynb',\n",
       " '30-regex-ref.ipynb',\n",
       " '30-T&D wrangling.ipynb',\n",
       " '40-numpy.ipynb',\n",
       " '50-pandas.ipynb',\n",
       " '70-http.ipynb',\n",
       " '90-pygame-1.ipynb',\n",
       " 'log.txt',\n",
       " 'Untitled.ipynb',\n",
       " 'wrd_xwcs.ipynb',\n",
       " 'XY-ZY修订.ipynb']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;32mdef\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mstat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS_ISREG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\programdata\\anaconda3\\lib\\genericpath.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.path.isfile??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `os.path.ispath` not found.\n"
     ]
    }
   ],
   "source": [
    "os.path.ispath??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".idea   False\n",
      "README.md   False\n",
      "参考书籍   False\n",
      "参考资料.md   False\n",
      "数据科学   False\n",
      "沧海遗珠   False\n",
      "编程学习   False\n",
      "项目练习   False\n"
     ]
    }
   ],
   "source": [
    "path=r'D:\\Python\\YeluAnalysis-master'\n",
    "f_p=os.listdir(path)\n",
    "to_txt=[]\n",
    "for i in f_p:\n",
    "    print(i+'   '+str(os.path.isfile(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".idea\n",
      "['encodings.xml', 'misc.xml', 'modules.xml', 'vcs.xml', 'workspace.xml', 'YeluAnalysis.iml']\n",
      "README.md\n",
      "README.md\n",
      "参考书籍\n",
      "['Python基础教程（第3版）.pdf', 'Python核心编程（第3版）.pdf', 'Python编程：从入门到实践.pdf', '人人都会数据分析：从生活实例学统计.pdf', '深入浅出统计学.pdf']\n",
      "参考资料.md\n",
      "参考资料.md\n",
      "数据科学\n",
      "['SQL', '大数据基础', '数据分析基础', '数据分析进阶', '统计学']\n",
      "沧海遗珠\n",
      "['data', 'DataFrame数据插入-nsert 的用法.ipynb', 'img', 'input和raw_input的区别.ipynb', 'pandas group 分组与agg聚合.ipynb', 'Pandas之函数sort_values.ipynb', 'Pandas之函数stack和unstack.ipynb', 'Pandas填充缺失值的方法.ipynb', 'Pandas学习笔记.ipynb', 'Pandas遍历数据表的方法.ipynb', 'Python中strip(),replace()和re.sub()用法.ipynb', 'Python中type和object间的关系.ipynb', '冒泡排序.ipynb', '列出当前目录下的所有文件和目录名.ipynb', '创建空列表和使用列表函数，哪种方式更效率.ipynb', '利用Pandas进行数据获取与数据预处理的基础实操.ipynb', '如何使用Python操作MySQL？.ipynb', '字典之函数get().ipynb', '将列表合并成字典.ipynb', '计算x的n次方.ipynb', '计算阶乘n!.ipynb', '选出每种产品最高价格的三条记录与最低价格的三条记录', '通过游戏汉诺塔理解递归算法.ipynb']\n",
      "编程学习\n",
      "['code', 'data', 'img', '三方库', '语言基础']\n",
      "项目练习\n",
      "['应用脚本', '爬虫工程', '面试刷题']\n"
     ]
    }
   ],
   "source": [
    "path=r'D:\\Python\\YeluAnalysis-master'\n",
    "f_p=os.listdir(path)\n",
    "to_txt=[]\n",
    "for i in f_p:\n",
    "    print(i)\n",
    "    try:\n",
    "        print(os.listdir(path+'\\\\'+i))\n",
    "    except FileNotFoundError:\n",
    "        print(i)\n",
    "    except NotADirectoryError:\n",
    "        print(i)\n",
    "# 问题:\n",
    "#     1.根目录下的文件会列出来两次\n",
    "#     2.只能深入到一层子文件夹,如何通过递归列出所有层次的子文件夹及其下文件?\n",
    "#     3.显示的模式还不够清晰.改为列出完整路径."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Python\\YeluAnalysis-master\\.idea\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\encodings.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\misc.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\modules.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\vcs.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\workspace.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\YeluAnalysis.iml\n",
      "D:\\Python\\YeluAnalysis-master\\README.md\n",
      "D:\\Python\\YeluAnalysis-master\\参考书籍\n",
      "D:\\Python\\YeluAnalysis-master\\参考书籍\\Python基础教程（第3版）.pdf\n",
      "D:\\Python\\YeluAnalysis-master\\参考书籍\\Python核心编程（第3版）.pdf\n",
      "D:\\Python\\YeluAnalysis-master\\参考书籍\\Python编程：从入门到实践.pdf\n",
      "D:\\Python\\YeluAnalysis-master\\参考书籍\\人人都会数据分析：从生活实例学统计.pdf\n",
      "D:\\Python\\YeluAnalysis-master\\参考书籍\\深入浅出统计学.pdf\n",
      "D:\\Python\\YeluAnalysis-master\\参考资料.md\n",
      "D:\\Python\\YeluAnalysis-master\\数据科学\n",
      "D:\\Python\\YeluAnalysis-master\\数据科学\\SQL\n",
      "D:\\Python\\YeluAnalysis-master\\数据科学\\大数据基础\n",
      "D:\\Python\\YeluAnalysis-master\\数据科学\\数据分析基础\n",
      "D:\\Python\\YeluAnalysis-master\\数据科学\\数据分析进阶\n",
      "D:\\Python\\YeluAnalysis-master\\数据科学\\统计学\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\data\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\DataFrame数据插入-nsert 的用法.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\img\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\input和raw_input的区别.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\pandas group 分组与agg聚合.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\Pandas之函数sort_values.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\Pandas之函数stack和unstack.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\Pandas填充缺失值的方法.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\Pandas学习笔记.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\Pandas遍历数据表的方法.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\Python中strip(),replace()和re.sub()用法.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\Python中type和object间的关系.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\冒泡排序.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\列出当前目录下的所有文件和目录名.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\创建空列表和使用列表函数，哪种方式更效率.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\利用Pandas进行数据获取与数据预处理的基础实操.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\如何使用Python操作MySQL？.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\字典之函数get().ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\将列表合并成字典.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\计算x的n次方.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\计算阶乘n!.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\选出每种产品最高价格的三条记录与最低价格的三条记录\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\通过游戏汉诺塔理解递归算法.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\编程学习\n",
      "D:\\Python\\YeluAnalysis-master\\编程学习\\code\n",
      "D:\\Python\\YeluAnalysis-master\\编程学习\\data\n",
      "D:\\Python\\YeluAnalysis-master\\编程学习\\img\n",
      "D:\\Python\\YeluAnalysis-master\\编程学习\\三方库\n",
      "D:\\Python\\YeluAnalysis-master\\编程学习\\语言基础\n",
      "D:\\Python\\YeluAnalysis-master\\项目练习\n",
      "D:\\Python\\YeluAnalysis-master\\项目练习\\应用脚本\n",
      "D:\\Python\\YeluAnalysis-master\\项目练习\\爬虫工程\n",
      "D:\\Python\\YeluAnalysis-master\\项目练习\\面试刷题\n"
     ]
    }
   ],
   "source": [
    "path=r'D:\\Python\\YeluAnalysis-master'\n",
    "f_p=os.listdir(path)\n",
    "to_txt=[]\n",
    "for i in f_p:\n",
    "    print(path+'\\\\'+i)\n",
    "    try:\n",
    "        for j in os.listdir(path+'\\\\'+i):\n",
    "            print(path+'\\\\'+i+'\\\\'+j)\n",
    "    except FileNotFoundError:\n",
    "        print(i)\n",
    "    except NotADirectoryError:\n",
    "        pass #print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Python\\\\YeluAnalysis-master\\\\.idea',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\.idea\\\\encodings.xml',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\.idea\\\\misc.xml',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\.idea\\\\modules.xml',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\.idea\\\\vcs.xml',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\.idea\\\\workspace.xml',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\.idea\\\\YeluAnalysis.iml',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\README.md',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\参考书籍',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\参考书籍\\\\Python基础教程（第3版）.pdf',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\参考书籍\\\\Python核心编程（第3版）.pdf',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\参考书籍\\\\Python编程：从入门到实践.pdf',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\参考书籍\\\\人人都会数据分析：从生活实例学统计.pdf',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\参考书籍\\\\深入浅出统计学.pdf',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\参考资料.md',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\数据科学',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\数据科学\\\\SQL',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\数据科学\\\\大数据基础',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\数据科学\\\\数据分析基础',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\数据科学\\\\数据分析进阶',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\数据科学\\\\统计学',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\data',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\DataFrame数据插入-nsert 的用法.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\img',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\input和raw_input的区别.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\pandas group 分组与agg聚合.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\Pandas之函数sort_values.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\Pandas之函数stack和unstack.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\Pandas填充缺失值的方法.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\Pandas学习笔记.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\Pandas遍历数据表的方法.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\Python中strip(),replace()和re.sub()用法.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\Python中type和object间的关系.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\冒泡排序.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\列出当前目录下的所有文件和目录名.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\创建空列表和使用列表函数，哪种方式更效率.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\利用Pandas进行数据获取与数据预处理的基础实操.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\如何使用Python操作MySQL？.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\字典之函数get().ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\将列表合并成字典.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\计算x的n次方.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\计算阶乘n!.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\选出每种产品最高价格的三条记录与最低价格的三条记录',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\通过游戏汉诺塔理解递归算法.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\编程学习',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\编程学习\\\\code',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\编程学习\\\\data',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\编程学习\\\\img',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\编程学习\\\\三方库',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\编程学习\\\\语言基础',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\项目练习',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\项目练习\\\\应用脚本',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\项目练习\\\\爬虫工程',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\项目练习\\\\面试刷题']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=r'D:\\Python\\YeluAnalysis-master'\n",
    "f_p=os.listdir(path)\n",
    "txt=[]\n",
    "for i in f_p:\n",
    "    #print(path+'\\\\'+i)\n",
    "    txt.append(path+'\\\\'+i)\n",
    "    try:\n",
    "        for j in os.listdir(path+'\\\\'+i):\n",
    "            #print(path+'\\\\'+i+'\\\\'+j)\n",
    "            txt.append(path+'\\\\'+i+'\\\\'+j)\n",
    "    except FileNotFoundError:\n",
    "        #print(i)\n",
    "        txt.append(i)\n",
    "    except NotADirectoryError: # 对于某些类型,如.md,会错误判断为目录\n",
    "        pass #print(i)\n",
    "txt\n",
    "# 问题:\n",
    "#     1.根目录下的文件会列出来两次====已经解决\n",
    "#     2.只能深入到一层子文件夹,如何通过递归列出所有层次的子文件夹及其下文件?-----how?\n",
    "#     3.显示的模式还不够清晰.改为列出完整路径.===已经解决"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Python\\\\YeluAnalysis-master\\\\.idea',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\.idea\\\\encodings.xml',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\.idea\\\\misc.xml',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\.idea\\\\modules.xml',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\.idea\\\\vcs.xml',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\.idea\\\\workspace.xml',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\.idea\\\\YeluAnalysis.iml',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\README.md',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\参考书籍',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\参考书籍\\\\Python基础教程（第3版）.pdf',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\参考书籍\\\\Python核心编程（第3版）.pdf',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\参考书籍\\\\Python编程：从入门到实践.pdf',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\参考书籍\\\\人人都会数据分析：从生活实例学统计.pdf',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\参考书籍\\\\深入浅出统计学.pdf',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\参考资料.md',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\数据科学',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\数据科学\\\\SQL',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\数据科学\\\\大数据基础',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\数据科学\\\\数据分析基础',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\数据科学\\\\数据分析进阶',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\数据科学\\\\统计学',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\data',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\DataFrame数据插入-nsert 的用法.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\img',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\input和raw_input的区别.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\pandas group 分组与agg聚合.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\Pandas之函数sort_values.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\Pandas之函数stack和unstack.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\Pandas填充缺失值的方法.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\Pandas学习笔记.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\Pandas遍历数据表的方法.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\Python中strip(),replace()和re.sub()用法.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\Python中type和object间的关系.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\冒泡排序.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\列出当前目录下的所有文件和目录名.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\创建空列表和使用列表函数，哪种方式更效率.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\利用Pandas进行数据获取与数据预处理的基础实操.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\如何使用Python操作MySQL？.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\字典之函数get().ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\将列表合并成字典.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\计算x的n次方.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\计算阶乘n!.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\选出每种产品最高价格的三条记录与最低价格的三条记录',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\沧海遗珠\\\\通过游戏汉诺塔理解递归算法.ipynb',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\编程学习',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\编程学习\\\\code',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\编程学习\\\\data',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\编程学习\\\\img',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\编程学习\\\\三方库',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\编程学习\\\\语言基础',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\项目练习',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\项目练习\\\\应用脚本',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\项目练习\\\\爬虫工程',\n",
       " 'D:\\\\Python\\\\YeluAnalysis-master\\\\项目练习\\\\面试刷题']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#先改为函数\n",
    "path=r'D:\\Python\\YeluAnalysis-master'\n",
    "def dirfp(path):\n",
    "    f_p=os.listdir(path)\n",
    "    txt=[]\n",
    "    for i in f_p:\n",
    "        #print(path+'\\\\'+i)\n",
    "        txt.append(path+'\\\\'+i)\n",
    "        try:\n",
    "            for j in os.listdir(path+'\\\\'+i):\n",
    "                #print(path+'\\\\'+i+'\\\\'+j)\n",
    "                txt.append(path+'\\\\'+i+'\\\\'+j)\n",
    "        except FileNotFoundError:\n",
    "            #print(i)\n",
    "            txt.append(i)\n",
    "        except NotADirectoryError:\n",
    "            pass #print(i)\n",
    "    return txt\n",
    "dirfp(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.idea', 'README.md', '参考书籍', '参考资料.md', '数据科学', '沧海遗珠', '编程学习', '项目练习']\n",
      ".idea\n",
      "D:\\Python\\YeluAnalysis-master\\.idea False\n",
      "['encodings.xml', 'misc.xml', 'modules.xml', 'vcs.xml', 'workspace.xml', 'YeluAnalysis.iml']\n",
      "encodings.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\encodings.xml True\n",
      "misc.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\misc.xml True\n",
      "modules.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\modules.xml True\n",
      "vcs.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\vcs.xml True\n",
      "workspace.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\workspace.xml True\n",
      "YeluAnalysis.iml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\YeluAnalysis.iml True\n"
     ]
    }
   ],
   "source": [
    "# 然后改为递归\n",
    "def dirfp(path):\n",
    "    f_p=os.listdir(path)\n",
    "    print(f_p)\n",
    "    txt=[]\n",
    "    for i in f_p:\n",
    "        print(i)\n",
    "        print(path+'\\\\'+i,os.path.isfile(path+'\\\\'+i))\n",
    "        #txt.append(path+'\\\\'+i)\n",
    "        try:\n",
    "            for j in os.listdir(path+'\\\\'+i):\n",
    "                return dirfp(path+'\\\\'+i)\n",
    "        except FileNotFoundError:\n",
    "            print(i)\n",
    "            #txt.append(i)\n",
    "        except NotADirectoryError:\n",
    "            pass #print(i)\n",
    "path=r'D:\\Python\\YeluAnalysis-master'\n",
    "dirfp(path)\n",
    "# 中文文件夹不能列出来了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Python\\YeluAnalysis-master\\.idea\\encodings.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\misc.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\modules.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\vcs.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\workspace.xml\n",
      "D:\\Python\\YeluAnalysis-master\\.idea\\YeluAnalysis.iml\n",
      "D:\\Python\\YeluAnalysis-master\\参考书籍\\Python基础教程（第3版）.pdf\n",
      "D:\\Python\\YeluAnalysis-master\\参考书籍\\Python核心编程（第3版）.pdf\n",
      "D:\\Python\\YeluAnalysis-master\\参考书籍\\Python编程：从入门到实践.pdf\n",
      "D:\\Python\\YeluAnalysis-master\\参考书籍\\人人都会数据分析：从生活实例学统计.pdf\n",
      "D:\\Python\\YeluAnalysis-master\\参考书籍\\深入浅出统计学.pdf\n",
      "D:\\Python\\YeluAnalysis-master\\数据科学\\SQL\n",
      "D:\\Python\\YeluAnalysis-master\\数据科学\\大数据基础\n",
      "D:\\Python\\YeluAnalysis-master\\数据科学\\数据分析基础\n",
      "D:\\Python\\YeluAnalysis-master\\数据科学\\数据分析进阶\n",
      "D:\\Python\\YeluAnalysis-master\\数据科学\\统计学\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\data\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\DataFrame数据插入-nsert 的用法.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\img\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\input和raw_input的区别.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\pandas group 分组与agg聚合.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\Pandas之函数sort_values.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\Pandas之函数stack和unstack.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\Pandas填充缺失值的方法.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\Pandas学习笔记.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\Pandas遍历数据表的方法.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\Python中strip(),replace()和re.sub()用法.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\Python中type和object间的关系.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\冒泡排序.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\列出当前目录下的所有文件和目录名.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\创建空列表和使用列表函数，哪种方式更效率.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\利用Pandas进行数据获取与数据预处理的基础实操.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\如何使用Python操作MySQL？.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\字典之函数get().ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\将列表合并成字典.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\计算x的n次方.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\计算阶乘n!.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\选出每种产品最高价格的三条记录与最低价格的三条记录\n",
      "D:\\Python\\YeluAnalysis-master\\沧海遗珠\\通过游戏汉诺塔理解递归算法.ipynb\n",
      "D:\\Python\\YeluAnalysis-master\\编程学习\\code\n",
      "D:\\Python\\YeluAnalysis-master\\编程学习\\data\n",
      "D:\\Python\\YeluAnalysis-master\\编程学习\\img\n",
      "D:\\Python\\YeluAnalysis-master\\编程学习\\三方库\n",
      "D:\\Python\\YeluAnalysis-master\\编程学习\\语言基础\n",
      "D:\\Python\\YeluAnalysis-master\\项目练习\\应用脚本\n",
      "D:\\Python\\YeluAnalysis-master\\项目练习\\爬虫工程\n",
      "D:\\Python\\YeluAnalysis-master\\项目练习\\面试刷题\n"
     ]
    }
   ],
   "source": [
    "#先改为函数\n",
    "path=r'D:\\Python\\YeluAnalysis-master'\n",
    "f_p=os.listdir(path)\n",
    "txt=[]\n",
    "for i in f_p:\n",
    "    #print(path+'\\\\'+i)\n",
    "    #txt.append(path+'\\\\'+i)\n",
    "    try:\n",
    "        for j in os.listdir(path+'\\\\'+i):\n",
    "            print(path+'\\\\'+i+'\\\\'+j)\n",
    "            #txt.append(path+'\\\\'+i+'\\\\'+j)\n",
    "    except FileNotFoundError:\n",
    "        print(i)\n",
    "        #txt.append(i)\n",
    "    except NotADirectoryError:\n",
    "        pass #print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bootmgr', 'hiberfil.sys', 'OEMSF', 'wgldr', 'wgldr.mbr', '~$SQL学习.docx', '~$表结构.docx', '表结构.docx']\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# 列出文件，不包含文件夹，返回列表\n",
    "def list_all_files(file_path):\n",
    "    return [f for f in listdir(file_path)if isfile(join(file_path, f))]\n",
    "\n",
    "# 列出所有信息，包括文件，返回列表\n",
    "def list_all(file_path):\n",
    "    return listdir(file_path)\n",
    "#  调用\n",
    "print(list_all_files(\"C:\\\\\"))\n",
    "#\n",
    "#————————————————\n",
    "#版权声明：本文为CSDN博主「疏林玉露」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。\n",
    "#原文链接：https://blog.csdn.net/u012996583/article/details/42521651"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文件读写\n",
    "# 文件(file)   \n",
    "2020.03.06 reviewed   \n",
    "20200719 将 20-file.ipynb 整个文档合并过来.      \n",
    "        \n",
    "  要使用文本文件中的信息，首先需要将信息读取到内存中.为此，你可以一次性读取文件的全部内容，也可以以每次一行的方式逐步读取--当文件过大以至于内存不够用时,必须使用后一种方法."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从文件中读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a message.\n",
      "pi=3.1415926\n",
      "and\n",
      "so\n",
      "on\n",
      "涓�鏂囧瓧绗�\n"
     ]
    }
   ],
   "source": [
    "# 查看文件内容\n",
    "# windows下使用 !type查看\n",
    "# linux下使用 !cat 查看\n",
    "!type data\\test.txt\n",
    "# 中文出现乱码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取整个文件   \n",
    "Python 中的 open 函数用来从磁盘读取文件. 相关参数及作用可参见函数说明."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclosefd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mopener\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Open file and return a stream.  Raise OSError upon failure.\n",
       "\n",
       "file is either a text or byte string giving the name (and the path\n",
       "if the file isn't in the current working directory) of the file to\n",
       "be opened or an integer file descriptor of the file to be\n",
       "wrapped. (If a file descriptor is given, it is closed when the\n",
       "returned I/O object is closed, unless closefd is set to False.)\n",
       "\n",
       "mode is an optional string that specifies the mode in which the file\n",
       "is opened. It defaults to 'r' which means open for reading in text\n",
       "mode.  Other common values are 'w' for writing (truncating the file if\n",
       "it already exists), 'x' for creating and writing to a new file, and\n",
       "'a' for appending (which on some Unix systems, means that all writes\n",
       "append to the end of the file regardless of the current seek position).\n",
       "In text mode, if encoding is not specified the encoding used is platform\n",
       "dependent: locale.getpreferredencoding(False) is called to get the\n",
       "current locale encoding. (For reading and writing raw bytes use binary\n",
       "mode and leave encoding unspecified.) The available modes are:\n",
       "\n",
       "========= ===============================================================\n",
       "Character Meaning\n",
       "--------- ---------------------------------------------------------------\n",
       "'r'       open for reading (default)\n",
       "'w'       open for writing, truncating the file first\n",
       "'x'       create a new file and open it for writing\n",
       "'a'       open for writing, appending to the end of the file if it exists\n",
       "'b'       binary mode\n",
       "'t'       text mode (default)\n",
       "'+'       open a disk file for updating (reading and writing)\n",
       "'U'       universal newline mode (deprecated)\n",
       "========= ===============================================================\n",
       "\n",
       "The default mode is 'rt' (open for reading text). For binary random\n",
       "access, the mode 'w+b' opens and truncates the file to 0 bytes, while\n",
       "'r+b' opens the file without truncation. The 'x' mode implies 'w' and\n",
       "raises an `FileExistsError` if the file already exists.\n",
       "\n",
       "Python distinguishes between files opened in binary and text modes,\n",
       "even when the underlying operating system doesn't. Files opened in\n",
       "binary mode (appending 'b' to the mode argument) return contents as\n",
       "bytes objects without any decoding. In text mode (the default, or when\n",
       "'t' is appended to the mode argument), the contents of the file are\n",
       "returned as strings, the bytes having been first decoded using a\n",
       "platform-dependent encoding or using the specified encoding if given.\n",
       "\n",
       "'U' mode is deprecated and will raise an exception in future versions\n",
       "of Python.  It has no effect in Python 3.  Use newline to control\n",
       "universal newlines mode.\n",
       "\n",
       "buffering is an optional integer used to set the buffering policy.\n",
       "Pass 0 to switch buffering off (only allowed in binary mode), 1 to select\n",
       "line buffering (only usable in text mode), and an integer > 1 to indicate\n",
       "the size of a fixed-size chunk buffer.  When no buffering argument is\n",
       "given, the default buffering policy works as follows:\n",
       "\n",
       "* Binary files are buffered in fixed-size chunks; the size of the buffer\n",
       "  is chosen using a heuristic trying to determine the underlying device's\n",
       "  \"block size\" and falling back on `io.DEFAULT_BUFFER_SIZE`.\n",
       "  On many systems, the buffer will typically be 4096 or 8192 bytes long.\n",
       "\n",
       "* \"Interactive\" text files (files for which isatty() returns True)\n",
       "  use line buffering.  Other text files use the policy described above\n",
       "  for binary files.\n",
       "\n",
       "encoding is the name of the encoding used to decode or encode the\n",
       "file. This should only be used in text mode. The default encoding is\n",
       "platform dependent, but any encoding supported by Python can be\n",
       "passed.  See the codecs module for the list of supported encodings.\n",
       "\n",
       "errors is an optional string that specifies how encoding errors are to\n",
       "be handled---this argument should not be used in binary mode. Pass\n",
       "'strict' to raise a ValueError exception if there is an encoding error\n",
       "(the default of None has the same effect), or pass 'ignore' to ignore\n",
       "errors. (Note that ignoring encoding errors can lead to data loss.)\n",
       "See the documentation for codecs.register or run 'help(codecs.Codec)'\n",
       "for a list of the permitted encoding error strings.\n",
       "\n",
       "newline controls how universal newlines works (it only applies to text\n",
       "mode). It can be None, '', '\\n', '\\r', and '\\r\\n'.  It works as\n",
       "follows:\n",
       "\n",
       "* On input, if newline is None, universal newlines mode is\n",
       "  enabled. Lines in the input can end in '\\n', '\\r', or '\\r\\n', and\n",
       "  these are translated into '\\n' before being returned to the\n",
       "  caller. If it is '', universal newline mode is enabled, but line\n",
       "  endings are returned to the caller untranslated. If it has any of\n",
       "  the other legal values, input lines are only terminated by the given\n",
       "  string, and the line ending is returned to the caller untranslated.\n",
       "\n",
       "* On output, if newline is None, any '\\n' characters written are\n",
       "  translated to the system default line separator, os.linesep. If\n",
       "  newline is '' or '\\n', no translation takes place. If newline is any\n",
       "  of the other legal values, any '\\n' characters written are translated\n",
       "  to the given string.\n",
       "\n",
       "If closefd is False, the underlying file descriptor will be kept open\n",
       "when the file is closed. This does not work when a file name is given\n",
       "and must be True in that case.\n",
       "\n",
       "A custom opener can be used by passing a callable as *opener*. The\n",
       "underlying file descriptor for the file object is then obtained by\n",
       "calling *opener* with (*file*, *flags*). *opener* must return an open\n",
       "file descriptor (passing os.open as *opener* results in functionality\n",
       "similar to passing None).\n",
       "\n",
       "open() returns a file object whose type depends on the mode, and\n",
       "through which the standard file operations such as reading and writing\n",
       "are performed. When open() is used to open a file in a text mode ('w',\n",
       "'r', 'wt', 'rt', etc.), it returns a TextIOWrapper. When used to open\n",
       "a file in a binary mode, the returned class varies: in read binary\n",
       "mode, it returns a BufferedReader; in write binary and append binary\n",
       "modes, it returns a BufferedWriter, and in read/write mode, it returns\n",
       "a BufferedRandom.\n",
       "\n",
       "It is also possible to use a string or bytearray as a file for both\n",
       "reading and writing. For strings StringIO can be used like a file\n",
       "opened in a text mode, and for bytes a BytesIO can be used like a file\n",
       "opened in a binary mode.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "open??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a message.\n",
      "pi=3.1415926\n",
      "and\n",
      "so\n",
      "on\n"
     ]
    }
   ],
   "source": [
    "# 使用python 打开(不含中文字符的)文件 \n",
    "# 使用相对路径,使用双斜杠\n",
    "with open('data\\\\test1.txt') as file_object:\n",
    "    contents = file_object.read()\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'gbk' codec can't decode byte 0xad in position 49: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-068bfff02641>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 对于含有中文字符的\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/test.txt'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#使用反斜杠 #提示有gbk编码的中文,打开看实际是utf-8的编码\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcontents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 有中文无法正确读取\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'gbk' codec can't decode byte 0xad in position 49: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "# 对于含有中文字符的\n",
    "with open('data/test.txt') as file_object: #使用反斜杠 #提示有gbk编码的中文,打开看实际是utf-8的编码\n",
    "    contents = file_object.read()\n",
    "print(contents)\n",
    "# 有中文无法正确读取\n",
    "# gbk编码的中文,需要改变编码为utf8,并在open函数的参数中指定编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a message.\n",
      "pi=3.1415926\n",
      "and\n",
      "so\n",
      "on\n",
      "中文字符\n"
     ]
    }
   ],
   "source": [
    "# open 函数增加参数encoding='utf-8' 能够正常打开含有汉字的文档了-- 但并不是所有中文文件增加了该参数都能打开\n",
    "# 有时候需要使用文本编辑器,如 notepad++, vscode 等等,打开文件后,使用另存为方法修改编码为 utf-8 等等方法进行预处理\n",
    "with open('data/test.txt','r',encoding='utf-8') as file_object: #使用反斜杠 \n",
    "    contents = file_object.read()\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a message.\n",
      "pi=3.1415926\n",
      "and\n",
      "so\n",
      "on\n",
      "中文字符\n"
     ]
    }
   ],
   "source": [
    "with open('data/test2.txt') as file_object: #使用反斜杠 # 打开test1.txt,另存为时,改为ascii编码,不再报错,并且中文显示正常了.\n",
    "    contents = file_object.read()\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关于编码(特别是中文编码)的坑还有很多\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Chinese_People's Republic of China.936\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_CTYPE, 'chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'gbk' codec can't decode byte 0xad in position 49: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-068bfff02641>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 对于含有中文字符的\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/test.txt'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#使用反斜杠 #提示有gbk编码的中文,打开看实际是utf-8的编码\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcontents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 有中文无法正确读取\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'gbk' codec can't decode byte 0xad in position 49: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "# 对于含有中文字符的\n",
    "with open('data/test.txt') as file_object: #使用反斜杠 #提示有gbk编码的中文,打开看实际是utf-8的编码\n",
    "    contents = file_object.read()\n",
    "print(contents)\n",
    "# 有中文无法正确读取\n",
    "# gbk编码的中文,需要改变编码为utf8,并在open函数的参数中指定编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文件路径  \n",
    "根据你组织文件的方式，有时可能要打开不在程序文件所属目录中的文件.   \n",
    "要让 Python 打开不与程序文件位于同一个目录中的文件，需要提供**文件路径** ，它让 Python 到系统的特定位置\n",
    "去查找.    \n",
    "\n",
    "* **相对路径**   \n",
    "  使用相对文件路径来打开该文件夹中的文件。   \n",
    "  相对文件路径让 Python 到指定的位置去查找，而该位置是相对于当前运行的程序所在目录的．　\n",
    "\n",
    "* **绝对路径**   \n",
    "  还可以将文件在计算机中的准确位置告诉 Python ，这样就不用关心当前运行的程序存储在什么地方了。这称为**绝对文件路径**.   \n",
    "  在相对路径行不通时，可使用绝对路径.   \n",
    "  例如，如果 text_files 并不在文件夹 python_work 中, 而在文件夹 other_files 中, 则向 open() 传递路径 'text_files/ filename.txt' 行不通，因为 Python 只在文件夹 python_work 中查找该位置. 为明确地指出你希望 Python 到哪里去查找，你需要提供完整的路径.    \n",
    "  绝对路径通常比相对路径更长，因此将其存储在一个变量中，再将该变量传递给 open() 会有所帮助.\n",
    "\n",
    "**注意** 　    \n",
    "Windows 系统有时能够正确地解读文件路径中的斜杠. 如果你使用的是 Windows 系统，且结果不符合预期，请确保在文件路径中使用的是反斜杠,或者使用双斜杠,或者在路径字符串前加了r. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逐行读取\n",
    "读取文件时，常常需要检查其中的每一行：你可能要在文件中查找特定的信息，或者要以某种方式修改文件中的文本。例如，你可能要遍历一个包含天气数据的文件，并使用天气描述中包含字样 sunny 的行。在新闻报道中，你可能会查找包含标签 <headline> 的行，并按特定的格式设置它。\n",
    "要以每次一行的方式检查文件，可对文件对象使用 for 循环："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a message.\n",
      "\n",
      "pi=3.1415926\n",
      "\n",
      "and\n",
      "\n",
      "so\n",
      "\n",
      "on\n",
      "\n",
      "中文字符\n"
     ]
    }
   ],
   "source": [
    "filename = r'D:\\Py\\note\\data\\test2.txt' # 路径前加r\n",
    "with open(filename) as file_object:\n",
    "    for line in file_object:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 上述代码打印每一行时，发现空白行更多了.   \n",
    "为何会出现这些空白行呢？因为在这个文件中，每行的末尾都有一个看不见的换行符，而 print 语句结束后也会加上一个换行符，因此每行末尾都有两个换行符：一个来自文件，另一\n",
    "个来自 print 语句。要消除这些多余的空白行，可在 print 语句中使用 rstrip() ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a message.\n",
      "pi=3.1415926\n",
      "and\n",
      "so\n",
      "on\n",
      "中文字符\n"
     ]
    }
   ],
   "source": [
    "filename = 'D:\\\\Py\\\\note\\\\data\\\\test2.txt' # 使用双斜杠转义\n",
    "with open(filename) as file_object:\n",
    "    for line in file_object:\n",
    "        print(line.rstrip()) # rstrip()函数,消除字符串右边的各类空白"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 为了进一步使用读取到的文件,还可以将读取到的文件保存到一个变量中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 46\n",
      "this is a message.\n",
      "pi=3.1415926\n",
      "and\n",
      "so\n",
      "on\n",
      "中文字符\n"
     ]
    }
   ],
   "source": [
    "filename = 'D:/Py/note/data/test2.txt' # 使用反斜杠\n",
    "with open(filename) as file_object:\n",
    "    lines = file_object.read()             # 使用read()方法获取到文件里的内容,并赋值给lines #这是一个字符串类型\n",
    "print(type(lines),len(lines))\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 保存为字符串类型的变量之后,就可以利用字符串的相关方法(特别是使用正则表达式方法)对其进行各种处理了."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 写入文件\n",
    "保存数据的最简单的方式之一是将其写入到文件中.    \n",
    "通过将输出写入文件，即便关闭包含程序输出的终端窗口，这些输出也依然存在：你可以在程序结束运行后查看这些输出，可与别人分享输出文件，还可编写程序来将这些输出读取到内存中并进行处理. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 写入到空文件   \n",
    "   新建文本文件并保存内容.如果有相同名称的文件,会覆盖,并且不会有提示--请确保没有同名文件,或者原来的文件已没有用处.   \n",
    "   可以使用OS模块中判断是否存在同名文件的方法来处理这种情况."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/programming.txt'\n",
    "with open(filename, 'w') as file_object:\n",
    "    file_object.write(\"I love programming.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love programming.3\n"
     ]
    }
   ],
   "source": [
    "with open('data\\\\programming.txt') as file_object:\n",
    "    contents = file_object.read()\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 写入多行\n",
    "函数 write() 不会在你写入的文本末尾添加换行符，因此如果你写入多行时没有指定换行符，文件看起来可能不是你希望的那样.\n",
    "要让每个字符串都单独占一行，需要在 write() 语句中包含换行符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/programming.txt'\n",
    "with open(filename, 'w') as file_object:\n",
    "    file_object.write(\"I love programming.\\n\")\n",
    "    file_object.write(\"I love creating new games.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love programming.\n",
      "I love creating new games.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/programming.txt') as file_object:\n",
    "    contents = file_object.read()\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 附加到文件\n",
    "如果你要给文件添加内容，而不是覆盖原有的内容，可以以 **附加模式** 打开文件(给open()函数传入'a'参数)。   \n",
    "你以附加模式打开文件时， Python 不会在返回文件对象前清空文件，而你写入到文件的行都将添加到文件末尾。如果指定的文件不存在， Python 将为你创建一个空文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/programming.txt'\n",
    "with open(filename, 'a') as file_object:\n",
    "    file_object.write(\"I also love finding meaning in large datasets.\\n\")\n",
    "    file_object.write(\"I love creating apps that can run in a browser.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love programming.\n",
      "I love creating new games.\n",
      "I also love finding meaning in large datasets.\n",
      "I love creating apps that can run in a browser.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/programming.txt') as file_object:\n",
    "    contents = file_object.read()\n",
    "print(contents)\n",
    "# 上一个cell的命令运行了两次,所以会有重复内容."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件对象的操作方法\n",
    "参考:https://blog.csdn.net/slwhy/article/details/78698017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 文件的打开模式\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr><th><span><strong><span>文件模式</span></strong></span></th><th><span><strong><span>说明</span></strong></span></th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><span><strong><span>r</span></strong></span></td>\n",
    "<td><span><strong><span>以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。</span></strong></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span><strong><span>rU,Ua</span></strong></span></td>\n",
    "<td><span><strong><span>以读方式打开，同时提供通用换行支持</span></strong></span></td>\n",
    "\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span><strong><span>w</span></strong></span></td>\n",
    "<td><span><strong><span>打开一个文件只用于写入。如果该文件已存在则,原文件会被清空，如果该文件不存在，创建新文件。</span></strong></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span><strong><span>a</span></strong></span></td>\n",
    "<td><span><strong><span>打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。</span></strong></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span><strong><span>rb</span></strong></span></td>\n",
    "<td><span><strong><span>以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。</span></strong></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span><strong><span>wb</span></strong></span></td>\n",
    "<td><span><strong><span>以二进制格式打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。</span></strong></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span><strong><span>ab</span></strong></span></td>\n",
    "<td><span><strong><span>以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。</span></strong></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span><strong><span>r+</span></strong></span></td>\n",
    "<td><span><strong><span>打开一个文件用于读写。文件指针将会放在文件的开头。</span></strong></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span><strong><span>w+</span></strong></span></td>\n",
    "<td><span><strong><span>打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。</span></strong></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span><strong><span>a+</span></strong></span></td>\n",
    "<td><span><strong><span>打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。</span></strong></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span><strong><span>rb+</span></strong></span></td>\n",
    "<td><span><strong><span>以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。</span></strong></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span><strong><span>wb+</span></strong></span></td>\n",
    "<td><span><strong><span>以二进制格式打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。</span></strong></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><span><strong><span>ab+</span></strong></span></td>\n",
    "<td><span><strong><span>以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。</span></strong></span></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学习对excel及csv文件进行操作\n",
    "csv 模块包含在 Python 标准库中，可用于分析 CSV 文件中的数据行，让我们能够快速提取感兴趣的值。   \n",
    "但实际上pandas更适合进行txt,csv,excel乃至JSON,HDF5等等各种格式数据的读取写入,并且操作更加简洁高效."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用csv模块进行读写\n",
    "导入模块 csv 后，我们将要使用的文件的名称存储在 filename 中。接下来，我们打开这个文件，并将结果文件对象存储在 f 中。然后，我们调用 csv.reader() ，并将前面存储的文件对象作为实参传递给它，从而创建一个与该文件相关联的阅读器（ reader ）对象。我们将这个阅读器对象存储在 reader 中。   \n",
    "模块 csv 包含函数 next() ，调用它并将阅读器对象传递给它时，它将返回文件中的下一行。在前面的代码中，我们只调用了 next() 一次，因此得到的是文件的第一行，其中包含文件头。我们将返回的数据存储在 header_row 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "filename = 'data/csv1.csv'\n",
    "with open(filename) as f:\n",
    "    reader = csv.reader(f)\n",
    "    header_row = next(reader)\n",
    "print(header_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1']\n",
      "['2']\n",
      "['3']\n",
      "['a']\n",
      "['b']\n",
      "['c']\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-f0189ad8c260>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# for 循环大于行数,报错 StopIteration                             Traceback (most recent call last)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 使用循环依次访问每一行\n",
    "import csv\n",
    "filename = 'data/csv1.csv'\n",
    "with open(filename) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i in range(7): # for 循环大于行数,报错 StopIteration                             Traceback (most recent call last)\n",
    "        row = next(reader)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-145-55bd1cf1fe09>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-145-55bd1cf1fe09>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    print(row) #csv模块的reader()函数,无法像python的reader()函数对文本文件那样,逐行读取?\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "filename = 'data/csv1.csv'\n",
    "with open(filename) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "    print(row) #csv模块的reader()函数,无法像python的reader()函数对文本文件那样,逐行读取?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "a\n",
      "b\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "# 把csv当作文本处理的时候,还是可以逐行访问的.\n",
    "with open(filename) as f:\n",
    "    for line in f:\n",
    "        print(line.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 读取csv   \n",
    "\n",
    "* 写入csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用pandas模块对csv文件进行读写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  2\n",
       "2  3\n",
       "3  a\n",
       "4  b\n",
       "5  c"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('data/csv1.csv',sep=',',header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIO\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mAnyStr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'infer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmangle_dupe_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mconverters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrue_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfalse_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskipinitialspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskipfooter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeep_default_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mna_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskip_blank_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeep_date_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdate_parser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcache_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0miterator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'infer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mthousands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mb'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlineterminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mquoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcomment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdialect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwarn_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfloat_precision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Read a comma-separated values (csv) file into DataFrame.\n",
       "\n",
       "Also supports optionally iterating or breaking of the file\n",
       "into chunks.\n",
       "\n",
       "Additional help can be found in the online docs for\n",
       "`IO Tools <http://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "filepath_or_buffer : str, path object or file-like object\n",
       "    Any valid string path is acceptable. The string could be a URL. Valid\n",
       "    URL schemes include http, ftp, s3, and file. For file URLs, a host is\n",
       "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
       "\n",
       "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
       "\n",
       "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
       "    a file handler (e.g. via builtin ``open`` function) or ``StringIO``.\n",
       "sep : str, default ','\n",
       "    Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
       "    the separator, but the Python parsing engine can, meaning the latter will\n",
       "    be used and automatically detect the separator by Python's builtin sniffer\n",
       "    tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
       "    different from ``'\\s+'`` will be interpreted as regular expressions and\n",
       "    will also force the use of the Python parsing engine. Note that regex\n",
       "    delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
       "delimiter : str, default ``None``\n",
       "    Alias for sep.\n",
       "header : int, list of int, default 'infer'\n",
       "    Row number(s) to use as the column names, and the start of the\n",
       "    data.  Default behavior is to infer the column names: if no names\n",
       "    are passed the behavior is identical to ``header=0`` and column\n",
       "    names are inferred from the first line of the file, if column\n",
       "    names are passed explicitly then the behavior is identical to\n",
       "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
       "    replace existing names. The header can be a list of integers that\n",
       "    specify row locations for a multi-index on the columns\n",
       "    e.g. [0,1,3]. Intervening rows that are not specified will be\n",
       "    skipped (e.g. 2 in this example is skipped). Note that this\n",
       "    parameter ignores commented lines and empty lines if\n",
       "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
       "    data rather than the first line of the file.\n",
       "names : array-like, optional\n",
       "    List of column names to use. If file contains no header row, then you\n",
       "    should explicitly pass ``header=None``. Duplicates in this list are not\n",
       "    allowed.\n",
       "index_col : int, str, sequence of int / str, or False, default ``None``\n",
       "  Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
       "  string name or column index. If a sequence of int / str is given, a\n",
       "  MultiIndex is used.\n",
       "\n",
       "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
       "  column as the index, e.g. when you have a malformed file with delimiters at\n",
       "  the end of each line.\n",
       "usecols : list-like or callable, optional\n",
       "    Return a subset of the columns. If list-like, all elements must either\n",
       "    be positional (i.e. integer indices into the document columns) or strings\n",
       "    that correspond to column names provided either by the user in `names` or\n",
       "    inferred from the document header row(s). For example, a valid list-like\n",
       "    `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
       "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
       "    To instantiate a DataFrame from ``data`` with element order preserved use\n",
       "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
       "    in ``['foo', 'bar']`` order or\n",
       "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
       "    for ``['bar', 'foo']`` order.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the column\n",
       "    names, returning names where the callable function evaluates to True. An\n",
       "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
       "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
       "    parsing time and lower memory usage.\n",
       "squeeze : bool, default False\n",
       "    If the parsed data only contains one column then return a Series.\n",
       "prefix : str, optional\n",
       "    Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
       "mangle_dupe_cols : bool, default True\n",
       "    Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
       "    'X'...'X'. Passing in False will cause data to be overwritten if there\n",
       "    are duplicate names in the columns.\n",
       "dtype : Type name or dict of column -> type, optional\n",
       "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
       "    'c': 'Int64'}\n",
       "    Use `str` or `object` together with suitable `na_values` settings\n",
       "    to preserve and not interpret dtype.\n",
       "    If converters are specified, they will be applied INSTEAD\n",
       "    of dtype conversion.\n",
       "engine : {'c', 'python'}, optional\n",
       "    Parser engine to use. The C engine is faster while the python engine is\n",
       "    currently more feature-complete.\n",
       "converters : dict, optional\n",
       "    Dict of functions for converting values in certain columns. Keys can either\n",
       "    be integers or column labels.\n",
       "true_values : list, optional\n",
       "    Values to consider as True.\n",
       "false_values : list, optional\n",
       "    Values to consider as False.\n",
       "skipinitialspace : bool, default False\n",
       "    Skip spaces after delimiter.\n",
       "skiprows : list-like, int or callable, optional\n",
       "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
       "    at the start of the file.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the row\n",
       "    indices, returning True if the row should be skipped and False otherwise.\n",
       "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
       "skipfooter : int, default 0\n",
       "    Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
       "nrows : int, optional\n",
       "    Number of rows of file to read. Useful for reading pieces of large files.\n",
       "na_values : scalar, str, list-like, or dict, optional\n",
       "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
       "    per-column NA values.  By default the following values are interpreted as\n",
       "    NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
       "    '1.#IND', '1.#QNAN', 'N/A', 'NA', 'NULL', 'NaN', 'n/a', 'nan',\n",
       "    'null'.\n",
       "keep_default_na : bool, default True\n",
       "    Whether or not to include the default NaN values when parsing the data.\n",
       "    Depending on whether `na_values` is passed in, the behavior is as follows:\n",
       "\n",
       "    * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
       "      is appended to the default NaN values used for parsing.\n",
       "    * If `keep_default_na` is True, and `na_values` are not specified, only\n",
       "      the default NaN values are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are specified, only\n",
       "      the NaN values specified `na_values` are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are not specified, no\n",
       "      strings will be parsed as NaN.\n",
       "\n",
       "    Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
       "    `na_values` parameters will be ignored.\n",
       "na_filter : bool, default True\n",
       "    Detect missing value markers (empty strings and the value of na_values). In\n",
       "    data without any NAs, passing na_filter=False can improve the performance\n",
       "    of reading a large file.\n",
       "verbose : bool, default False\n",
       "    Indicate number of NA values placed in non-numeric columns.\n",
       "skip_blank_lines : bool, default True\n",
       "    If True, skip over blank lines rather than interpreting as NaN values.\n",
       "parse_dates : bool or list of int or names or list of lists or dict, default False\n",
       "    The behavior is as follows:\n",
       "\n",
       "    * boolean. If True -> try parsing the index.\n",
       "    * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
       "      each as a separate date column.\n",
       "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
       "      a single date column.\n",
       "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
       "      result 'foo'\n",
       "\n",
       "    If a column or index cannot be represented as an array of datetimes,\n",
       "    say because of an unparseable value or a mixture of timezones, the column\n",
       "    or index will be returned unaltered as an object data type. For\n",
       "    non-standard datetime parsing, use ``pd.to_datetime`` after\n",
       "    ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
       "    specify ``date_parser`` to be a partially-applied\n",
       "    :func:`pandas.to_datetime` with ``utc=True``. See\n",
       "    :ref:`io.csv.mixed_timezones` for more.\n",
       "\n",
       "    Note: A fast-path exists for iso8601-formatted dates.\n",
       "infer_datetime_format : bool, default False\n",
       "    If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
       "    format of the datetime strings in the columns, and if it can be inferred,\n",
       "    switch to a faster method of parsing them. In some cases this can increase\n",
       "    the parsing speed by 5-10x.\n",
       "keep_date_col : bool, default False\n",
       "    If True and `parse_dates` specifies combining multiple columns then\n",
       "    keep the original columns.\n",
       "date_parser : function, optional\n",
       "    Function to use for converting a sequence of string columns to an array of\n",
       "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
       "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
       "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
       "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
       "    string values from the columns defined by `parse_dates` into a single array\n",
       "    and pass that; and 3) call `date_parser` once for each row using one or\n",
       "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
       "    arguments.\n",
       "dayfirst : bool, default False\n",
       "    DD/MM format dates, international and European format.\n",
       "cache_dates : boolean, default True\n",
       "    If True, use a cache of unique, converted dates to apply the datetime\n",
       "    conversion. May produce significant speed-up when parsing duplicate\n",
       "    date strings, especially ones with timezone offsets.\n",
       "\n",
       "    .. versionadded:: 0.25.0\n",
       "iterator : bool, default False\n",
       "    Return TextFileReader object for iteration or getting chunks with\n",
       "    ``get_chunk()``.\n",
       "chunksize : int, optional\n",
       "    Return TextFileReader object for iteration.\n",
       "    See the `IO Tools docs\n",
       "    <http://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
       "    for more information on ``iterator`` and ``chunksize``.\n",
       "compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
       "    For on-the-fly decompression of on-disk data. If 'infer' and\n",
       "    `filepath_or_buffer` is path-like, then detect compression from the\n",
       "    following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
       "    decompression). If using 'zip', the ZIP file must contain only one data\n",
       "    file to be read in. Set to None for no decompression.\n",
       "\n",
       "    .. versionadded:: 0.18.1 support for 'zip' and 'xz' compression.\n",
       "\n",
       "thousands : str, optional\n",
       "    Thousands separator.\n",
       "decimal : str, default '.'\n",
       "    Character to recognize as decimal point (e.g. use ',' for European data).\n",
       "lineterminator : str (length 1), optional\n",
       "    Character to break file into lines. Only valid with C parser.\n",
       "quotechar : str (length 1), optional\n",
       "    The character used to denote the start and end of a quoted item. Quoted\n",
       "    items can include the delimiter and it will be ignored.\n",
       "quoting : int or csv.QUOTE_* instance, default 0\n",
       "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
       "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
       "doublequote : bool, default ``True``\n",
       "   When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
       "   whether or not to interpret two consecutive quotechar elements INSIDE a\n",
       "   field as a single ``quotechar`` element.\n",
       "escapechar : str (length 1), optional\n",
       "    One-character string used to escape other characters.\n",
       "comment : str, optional\n",
       "    Indicates remainder of line should not be parsed. If found at the beginning\n",
       "    of a line, the line will be ignored altogether. This parameter must be a\n",
       "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
       "    fully commented lines are ignored by the parameter `header` but not by\n",
       "    `skiprows`. For example, if ``comment='#'``, parsing\n",
       "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
       "    treated as the header.\n",
       "encoding : str, optional\n",
       "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
       "    standard encodings\n",
       "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
       "dialect : str or csv.Dialect, optional\n",
       "    If provided, this parameter will override values (default or not) for the\n",
       "    following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
       "    `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
       "    override values, a ParserWarning will be issued. See csv.Dialect\n",
       "    documentation for more details.\n",
       "error_bad_lines : bool, default True\n",
       "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
       "    default cause an exception to be raised, and no DataFrame will be returned.\n",
       "    If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
       "    returned.\n",
       "warn_bad_lines : bool, default True\n",
       "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
       "    \"bad line\" will be output.\n",
       "delim_whitespace : bool, default False\n",
       "    Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
       "    used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
       "    is set to True, nothing should be passed in for the ``delimiter``\n",
       "    parameter.\n",
       "\n",
       "    .. versionadded:: 0.18.1 support for the Python parser.\n",
       "\n",
       "low_memory : bool, default True\n",
       "    Internally process the file in chunks, resulting in lower memory use\n",
       "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
       "    types either set False, or specify the type with the `dtype` parameter.\n",
       "    Note that the entire file is read into a single DataFrame regardless,\n",
       "    use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
       "    (Only valid with C parser).\n",
       "memory_map : bool, default False\n",
       "    If a filepath is provided for `filepath_or_buffer`, map the file object\n",
       "    directly onto memory and access the data directly from there. Using this\n",
       "    option can improve performance because there is no longer any I/O overhead.\n",
       "float_precision : str, optional\n",
       "    Specifies which converter the C engine should use for floating-point\n",
       "    values. The options are `None` for the ordinary converter,\n",
       "    `high` for the high-precision converter, and `round_trip` for the\n",
       "    round-trip converter.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame or TextParser\n",
       "    A comma-separated values (csv) file is returned as two-dimensional\n",
       "    data structure with labeled axes.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
       "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
       "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\programdata\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv?\n",
    "#可查看更多参数及具体用法\n",
    "# sep 参数只能指定单个字符作为分隔符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 写入csv的方法--并不会有返回值,并且如果有重名文件会覆盖\n",
    "df.to_csv(r'test719\\to_csv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用pandas模块对excel文件进行读写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>分馆</th>\n",
       "      <th>学号</th>\n",
       "      <th>姓名</th>\n",
       "      <th>学院名称</th>\n",
       "      <th>专业名称</th>\n",
       "      <th>有图书未归还（截止到617）</th>\n",
       "      <th>有欠款未结清（截止到612）</th>\n",
       "      <th>是否需要办理离校手续</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>工学馆</td>\n",
       "      <td>A0255655005</td>\n",
       "      <td>徐xx</td>\n",
       "      <td>材料科学与工程学院</td>\n",
       "      <td>无机非金属材料工程</td>\n",
       "      <td>是</td>\n",
       "      <td>NaN</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>工学馆</td>\n",
       "      <td>A0255655055</td>\n",
       "      <td>蔡xx</td>\n",
       "      <td>材料科学与工程学院</td>\n",
       "      <td>无机非金属材料工程</td>\n",
       "      <td>是</td>\n",
       "      <td>NaN</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>工学馆</td>\n",
       "      <td>A0255655002</td>\n",
       "      <td>秦xx</td>\n",
       "      <td>材料科学与工程学院</td>\n",
       "      <td>无机非金属材料工程</td>\n",
       "      <td>是</td>\n",
       "      <td>NaN</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>工学馆</td>\n",
       "      <td>A0255654025</td>\n",
       "      <td>解xx</td>\n",
       "      <td>材料科学与工程学院</td>\n",
       "      <td>材料化学</td>\n",
       "      <td>是</td>\n",
       "      <td>NaN</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>工学馆</td>\n",
       "      <td>A0255652029</td>\n",
       "      <td>温xx</td>\n",
       "      <td>材料科学与工程学院</td>\n",
       "      <td>金属材料工程</td>\n",
       "      <td>是</td>\n",
       "      <td>NaN</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>工学馆</td>\n",
       "      <td>A0255655045</td>\n",
       "      <td>杨xx</td>\n",
       "      <td>材料科学与工程学院</td>\n",
       "      <td>无机非金属材料工程</td>\n",
       "      <td>是</td>\n",
       "      <td>NaN</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>工学馆</td>\n",
       "      <td>A0255653006</td>\n",
       "      <td>蒋xx</td>\n",
       "      <td>材料科学与工程学院</td>\n",
       "      <td>新能源材料与器件</td>\n",
       "      <td>是</td>\n",
       "      <td>NaN</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>工学馆</td>\n",
       "      <td>A0255655025</td>\n",
       "      <td>佟xx</td>\n",
       "      <td>材料科学与工程学院</td>\n",
       "      <td>生物医学工程（生物材料与人工器官方向）</td>\n",
       "      <td>是</td>\n",
       "      <td>NaN</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    分馆           学号   姓名       学院名称                 专业名称 有图书未归还（截止到617）  \\\n",
       "0  工学馆  A0255655005  徐xx  材料科学与工程学院            无机非金属材料工程              是   \n",
       "1  工学馆  A0255655055  蔡xx  材料科学与工程学院            无机非金属材料工程              是   \n",
       "2  工学馆  A0255655002  秦xx  材料科学与工程学院            无机非金属材料工程              是   \n",
       "3  工学馆  A0255654025  解xx  材料科学与工程学院                 材料化学              是   \n",
       "4  工学馆  A0255652029  温xx  材料科学与工程学院               金属材料工程              是   \n",
       "5  工学馆  A0255655045  杨xx  材料科学与工程学院            无机非金属材料工程              是   \n",
       "6  工学馆  A0255653006  蒋xx  材料科学与工程学院             新能源材料与器件              是   \n",
       "7  工学馆  A0255655025  佟xx  材料科学与工程学院  生物医学工程（生物材料与人工器官方向）              是   \n",
       "\n",
       "   有欠款未结清（截止到612） 是否需要办理离校手续  \n",
       "0             NaN          是  \n",
       "1             NaN          是  \n",
       "2             NaN          是  \n",
       "3             NaN          是  \n",
       "4             NaN          是  \n",
       "5             NaN          是  \n",
       "6             NaN          是  \n",
       "7             NaN          是  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接传入名即可读取excel文件--如果不在工作目录,需要更改工作目录或者传入包括完整路径的文件名\n",
    "df1 = pd.read_excel('副本材料科学与工程学院本科毕业生需办理离校手续清单.xlsx')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIO\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mAnyStr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'infer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmangle_dupe_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mconverters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrue_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfalse_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskipinitialspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskipfooter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeep_default_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mna_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mskip_blank_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeep_date_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdate_parser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcache_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0miterator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'infer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mthousands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdecimal\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlineterminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mquoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcomment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdialect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwarn_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfloat_precision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Read a comma-separated values (csv) file into DataFrame.\n",
       "\n",
       "Also supports optionally iterating or breaking of the file\n",
       "into chunks.\n",
       "\n",
       "Additional help can be found in the online docs for\n",
       "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "filepath_or_buffer : str, path object or file-like object\n",
       "    Any valid string path is acceptable. The string could be a URL. Valid\n",
       "    URL schemes include http, ftp, s3, and file. For file URLs, a host is\n",
       "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
       "\n",
       "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
       "\n",
       "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
       "    a file handler (e.g. via builtin ``open`` function) or ``StringIO``.\n",
       "sep : str, default ','\n",
       "    Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
       "    the separator, but the Python parsing engine can, meaning the latter will\n",
       "    be used and automatically detect the separator by Python's builtin sniffer\n",
       "    tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
       "    different from ``'\\s+'`` will be interpreted as regular expressions and\n",
       "    will also force the use of the Python parsing engine. Note that regex\n",
       "    delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
       "delimiter : str, default ``None``\n",
       "    Alias for sep.\n",
       "header : int, list of int, default 'infer'\n",
       "    Row number(s) to use as the column names, and the start of the\n",
       "    data.  Default behavior is to infer the column names: if no names\n",
       "    are passed the behavior is identical to ``header=0`` and column\n",
       "    names are inferred from the first line of the file, if column\n",
       "    names are passed explicitly then the behavior is identical to\n",
       "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
       "    replace existing names. The header can be a list of integers that\n",
       "    specify row locations for a multi-index on the columns\n",
       "    e.g. [0,1,3]. Intervening rows that are not specified will be\n",
       "    skipped (e.g. 2 in this example is skipped). Note that this\n",
       "    parameter ignores commented lines and empty lines if\n",
       "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
       "    data rather than the first line of the file.\n",
       "names : array-like, optional\n",
       "    List of column names to use. If the file contains a header row,\n",
       "    then you should explicitly pass ``header=0`` to override the column names.\n",
       "    Duplicates in this list are not allowed.\n",
       "index_col : int, str, sequence of int / str, or False, default ``None``\n",
       "  Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
       "  string name or column index. If a sequence of int / str is given, a\n",
       "  MultiIndex is used.\n",
       "\n",
       "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
       "  column as the index, e.g. when you have a malformed file with delimiters at\n",
       "  the end of each line.\n",
       "usecols : list-like or callable, optional\n",
       "    Return a subset of the columns. If list-like, all elements must either\n",
       "    be positional (i.e. integer indices into the document columns) or strings\n",
       "    that correspond to column names provided either by the user in `names` or\n",
       "    inferred from the document header row(s). For example, a valid list-like\n",
       "    `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
       "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
       "    To instantiate a DataFrame from ``data`` with element order preserved use\n",
       "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
       "    in ``['foo', 'bar']`` order or\n",
       "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
       "    for ``['bar', 'foo']`` order.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the column\n",
       "    names, returning names where the callable function evaluates to True. An\n",
       "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
       "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
       "    parsing time and lower memory usage.\n",
       "squeeze : bool, default False\n",
       "    If the parsed data only contains one column then return a Series.\n",
       "prefix : str, optional\n",
       "    Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
       "mangle_dupe_cols : bool, default True\n",
       "    Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
       "    'X'...'X'. Passing in False will cause data to be overwritten if there\n",
       "    are duplicate names in the columns.\n",
       "dtype : Type name or dict of column -> type, optional\n",
       "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
       "    'c': 'Int64'}\n",
       "    Use `str` or `object` together with suitable `na_values` settings\n",
       "    to preserve and not interpret dtype.\n",
       "    If converters are specified, they will be applied INSTEAD\n",
       "    of dtype conversion.\n",
       "engine : {'c', 'python'}, optional\n",
       "    Parser engine to use. The C engine is faster while the python engine is\n",
       "    currently more feature-complete.\n",
       "converters : dict, optional\n",
       "    Dict of functions for converting values in certain columns. Keys can either\n",
       "    be integers or column labels.\n",
       "true_values : list, optional\n",
       "    Values to consider as True.\n",
       "false_values : list, optional\n",
       "    Values to consider as False.\n",
       "skipinitialspace : bool, default False\n",
       "    Skip spaces after delimiter.\n",
       "skiprows : list-like, int or callable, optional\n",
       "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
       "    at the start of the file.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the row\n",
       "    indices, returning True if the row should be skipped and False otherwise.\n",
       "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
       "skipfooter : int, default 0\n",
       "    Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
       "nrows : int, optional\n",
       "    Number of rows of file to read. Useful for reading pieces of large files.\n",
       "na_values : scalar, str, list-like, or dict, optional\n",
       "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
       "    per-column NA values.  By default the following values are interpreted as\n",
       "    NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
       "    '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
       "    'nan', 'null'.\n",
       "keep_default_na : bool, default True\n",
       "    Whether or not to include the default NaN values when parsing the data.\n",
       "    Depending on whether `na_values` is passed in, the behavior is as follows:\n",
       "\n",
       "    * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
       "      is appended to the default NaN values used for parsing.\n",
       "    * If `keep_default_na` is True, and `na_values` are not specified, only\n",
       "      the default NaN values are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are specified, only\n",
       "      the NaN values specified `na_values` are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are not specified, no\n",
       "      strings will be parsed as NaN.\n",
       "\n",
       "    Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
       "    `na_values` parameters will be ignored.\n",
       "na_filter : bool, default True\n",
       "    Detect missing value markers (empty strings and the value of na_values). In\n",
       "    data without any NAs, passing na_filter=False can improve the performance\n",
       "    of reading a large file.\n",
       "verbose : bool, default False\n",
       "    Indicate number of NA values placed in non-numeric columns.\n",
       "skip_blank_lines : bool, default True\n",
       "    If True, skip over blank lines rather than interpreting as NaN values.\n",
       "parse_dates : bool or list of int or names or list of lists or dict, default False\n",
       "    The behavior is as follows:\n",
       "\n",
       "    * boolean. If True -> try parsing the index.\n",
       "    * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
       "      each as a separate date column.\n",
       "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
       "      a single date column.\n",
       "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
       "      result 'foo'\n",
       "\n",
       "    If a column or index cannot be represented as an array of datetimes,\n",
       "    say because of an unparseable value or a mixture of timezones, the column\n",
       "    or index will be returned unaltered as an object data type. For\n",
       "    non-standard datetime parsing, use ``pd.to_datetime`` after\n",
       "    ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
       "    specify ``date_parser`` to be a partially-applied\n",
       "    :func:`pandas.to_datetime` with ``utc=True``. See\n",
       "    :ref:`io.csv.mixed_timezones` for more.\n",
       "\n",
       "    Note: A fast-path exists for iso8601-formatted dates.\n",
       "infer_datetime_format : bool, default False\n",
       "    If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
       "    format of the datetime strings in the columns, and if it can be inferred,\n",
       "    switch to a faster method of parsing them. In some cases this can increase\n",
       "    the parsing speed by 5-10x.\n",
       "keep_date_col : bool, default False\n",
       "    If True and `parse_dates` specifies combining multiple columns then\n",
       "    keep the original columns.\n",
       "date_parser : function, optional\n",
       "    Function to use for converting a sequence of string columns to an array of\n",
       "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
       "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
       "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
       "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
       "    string values from the columns defined by `parse_dates` into a single array\n",
       "    and pass that; and 3) call `date_parser` once for each row using one or\n",
       "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
       "    arguments.\n",
       "dayfirst : bool, default False\n",
       "    DD/MM format dates, international and European format.\n",
       "cache_dates : bool, default True\n",
       "    If True, use a cache of unique, converted dates to apply the datetime\n",
       "    conversion. May produce significant speed-up when parsing duplicate\n",
       "    date strings, especially ones with timezone offsets.\n",
       "\n",
       "    .. versionadded:: 0.25.0\n",
       "iterator : bool, default False\n",
       "    Return TextFileReader object for iteration or getting chunks with\n",
       "    ``get_chunk()``.\n",
       "chunksize : int, optional\n",
       "    Return TextFileReader object for iteration.\n",
       "    See the `IO Tools docs\n",
       "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
       "    for more information on ``iterator`` and ``chunksize``.\n",
       "compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
       "    For on-the-fly decompression of on-disk data. If 'infer' and\n",
       "    `filepath_or_buffer` is path-like, then detect compression from the\n",
       "    following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
       "    decompression). If using 'zip', the ZIP file must contain only one data\n",
       "    file to be read in. Set to None for no decompression.\n",
       "thousands : str, optional\n",
       "    Thousands separator.\n",
       "decimal : str, default '.'\n",
       "    Character to recognize as decimal point (e.g. use ',' for European data).\n",
       "lineterminator : str (length 1), optional\n",
       "    Character to break file into lines. Only valid with C parser.\n",
       "quotechar : str (length 1), optional\n",
       "    The character used to denote the start and end of a quoted item. Quoted\n",
       "    items can include the delimiter and it will be ignored.\n",
       "quoting : int or csv.QUOTE_* instance, default 0\n",
       "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
       "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
       "doublequote : bool, default ``True``\n",
       "   When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
       "   whether or not to interpret two consecutive quotechar elements INSIDE a\n",
       "   field as a single ``quotechar`` element.\n",
       "escapechar : str (length 1), optional\n",
       "    One-character string used to escape other characters.\n",
       "comment : str, optional\n",
       "    Indicates remainder of line should not be parsed. If found at the beginning\n",
       "    of a line, the line will be ignored altogether. This parameter must be a\n",
       "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
       "    fully commented lines are ignored by the parameter `header` but not by\n",
       "    `skiprows`. For example, if ``comment='#'``, parsing\n",
       "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
       "    treated as the header.\n",
       "encoding : str, optional\n",
       "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
       "    standard encodings\n",
       "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
       "dialect : str or csv.Dialect, optional\n",
       "    If provided, this parameter will override values (default or not) for the\n",
       "    following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
       "    `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
       "    override values, a ParserWarning will be issued. See csv.Dialect\n",
       "    documentation for more details.\n",
       "error_bad_lines : bool, default True\n",
       "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
       "    default cause an exception to be raised, and no DataFrame will be returned.\n",
       "    If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
       "    returned.\n",
       "warn_bad_lines : bool, default True\n",
       "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
       "    \"bad line\" will be output.\n",
       "delim_whitespace : bool, default False\n",
       "    Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
       "    used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
       "    is set to True, nothing should be passed in for the ``delimiter``\n",
       "    parameter.\n",
       "low_memory : bool, default True\n",
       "    Internally process the file in chunks, resulting in lower memory use\n",
       "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
       "    types either set False, or specify the type with the `dtype` parameter.\n",
       "    Note that the entire file is read into a single DataFrame regardless,\n",
       "    use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
       "    (Only valid with C parser).\n",
       "memory_map : bool, default False\n",
       "    If a filepath is provided for `filepath_or_buffer`, map the file object\n",
       "    directly onto memory and access the data directly from there. Using this\n",
       "    option can improve performance because there is no longer any I/O overhead.\n",
       "float_precision : str, optional\n",
       "    Specifies which converter the C engine should use for floating-point\n",
       "    values. The options are `None` for the ordinary converter,\n",
       "    `high` for the high-precision converter, and `round_trip` for the\n",
       "    round-trip converter.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame or TextParser\n",
       "    A comma-separated values (csv) file is returned as two-dimensional\n",
       "    data structure with labeled axes.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
       "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
       "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "    \u001b[1;32mdef\u001b[0m \u001b[0mparser_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFilePathOrBuffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_sep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Column and Index Locations and Names\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"infer\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mmangle_dupe_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# General Parsing Configuration\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mconverters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mtrue_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mfalse_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mskipinitialspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mskipfooter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# NA and Missing Data Handling\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mkeep_default_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mna_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mskip_blank_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Datetime Handling\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mkeep_date_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mdate_parser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcache_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Iteration\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0miterator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Quoting, Compression, and File Format\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"infer\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mthousands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mdecimal\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\".\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mlineterminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mquotechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mquoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQUOTE_MINIMAL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcomment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mdialect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Error Handling\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mwarn_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Internal\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_c_parser_defaults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"low_memory\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mfloat_precision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# gh-23761\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m#\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# When a dialect is passed, it overrides any of the overlapping\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# parameters passed in directly. We don't want to warn if the\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# default parameters were passed in (since it probably means\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# that the user didn't pass them in explicitly in the first place).\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m#\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# \"delimiter\" is the annoying corner case because we alias it to\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# \"sep\" before doing comparison to the dialect values later on.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Thus, we need a flag to indicate that we need to \"override\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# the comparison to dialect values by checking if default values\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# for BOTH \"delimiter\" and \"sep\" were provided.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mdialect\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0msep_override\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdefault_sep\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msep_override\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msep_override\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Alias sep -> delimiter.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdelimiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mdelim_whitespace\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdefault_sep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34m\"Specified a delimiter with both sep and \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34m\"delim_whitespace=True; you can only \"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;34m\"specify one.\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mengine_specified\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mengine_specified\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdialect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdialect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mengine_specified\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine_specified\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mquotechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquotechar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mquoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquoting\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mskipinitialspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipinitialspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mlineterminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mskipfooter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipfooter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mtrue_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrue_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mfalse_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfalse_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mkeep_default_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_default_na\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mthousands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthousands\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mcomment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mkeep_date_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_date_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdate_parser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdate_parser\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mcache_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache_dates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0miterator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mconverters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemory_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mfloat_precision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat_precision\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mna_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_filter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mwarn_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_bad_lines\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mmangle_dupe_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmangle_dupe_cols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mskip_blank_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskip_blank_lines\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      d:\\programdata\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 该函数还有很多参数,可根据需要使用.\n",
    "pd.read_csv??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 写入excel\n",
    "# 简单的写入excel, 和写入csv并无区别\n",
    "df.to_excel('test719\\\\toexcel1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#当需要将多个df写入同一个excel的时候,需要将 excel 文件路径改为一个excel_writer对象, 然后分别将不同df写入不同的sheet\n",
    "writers=pd.ExcelWriter(path=r'test719\\multsheet.xlsx',engine='xlsxwriter')\n",
    "df1.to_excel(excel_writer=writers,sheet_name='名单',index=False,encoding='utf-8')\n",
    "df.to_excel(excel_writer=writers,sheet_name='sheet_1',index=False,encoding='utf-8')\n",
    "# 多个df导入到同一个excel的不同sheet\n",
    "writers.save()# 最后需要保存 excelwriter 对象才会写入磁盘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 更多关于使用pandas读写其他格式文件的方法参阅<利用python进行数据分析>第六章."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文件组织 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
